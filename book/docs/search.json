[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "Over the past few years, the development of excellent self-paced tutorials and training materials for undertaking digital scholarship and data science in libraries have proliferated online.\nFor library professionals who are relatively new to this area however, it can be hard to know where to begin! Without knowing a little bit about the context of how new technologies and methodologies are being deployed in research libraries, this dearth of resources can seem quite daunting. Even if you might have an idea of what learning you’d like to undertake, it can be difficult and time consuming to try and navigate the wealth of individual training resources out there on your own.\nDigital Scholarship & Data Science Topic Guides for Library Professionals (DS Topic Guides) are written for and by research library professionals across LIBER to help share some of our experience and knowledge and lower those barriers to entry for others!\nTake me to the Topic Guides"
  },
  {
    "objectID": "project-overview.html",
    "href": "project-overview.html",
    "title": "About",
    "section": "",
    "text": "Digital Scholarship & Data Science Topic Guides for Library Professionals is a project first undertaken in 2023 as a joint collaboration between the Digital Scholarship & Digital Cultural Heritage (DSDCH) and the Data Science in Libraries (DSLib). It is an open and collaboratively curated training reference resource that aims to:"
  },
  {
    "objectID": "project-overview.html#are-ds-topic-guides-for-me",
    "href": "project-overview.html#are-ds-topic-guides-for-me",
    "title": "About",
    "section": "Are DS Topic Guides for me?",
    "text": "Are DS Topic Guides for me?\nAre you someone working in or around research libraries with an interest in learning more about how to do cool and interesting things with digital collections and data at your institution? Wondering how data science techniques can help you in your work? Are you interested in gaining valuable digital literacy skills and knowledge to support emerging areas of modern scholarship such as Digital Humanities? Do you need some of the technology jargon you hear about these days demystified?\nThen this resource is for you!\nIt is very important to us that the guides here are inclusive and intellectually accessible, challenging but not terrifying and as such we focus primarily on an introductory audience where no programming or particular digital skills are required.\nThough written from the research library professional perspective we think these guides will be useful for anyone currently (or aspiring to be) working in and around digital collections and data in heritage institutions:\n\nLibrary & Information Science students\nProject managers\nDevelopers\nInformation specialists\nMetadata Managers\nSubject librarians\nSystem librarians\nInstitutional leadership\n\nAnd so many more!"
  },
  {
    "objectID": "project-overview.html#project-history",
    "href": "project-overview.html#project-history",
    "title": "About",
    "section": "Project History",
    "text": "Project History\nThe impetus for this project has its roots in LIBER member British Library’s Digital Scholarship Training Programme, where for over a decade now, Digital Curators there have maintained bespoke learning resources on digital scholarship tools and methods for internal use as part of their staff training courses, talks reading group and Hack & Yacks. The team there has been looking for places to share these existing resources and expertise more widely with the sector in a dedicated collaborative learning space online.\nMeanwhile, both LIBER working groups noted that while the exponential expansion of digital collections, and the computational methods and tools to interact with them presented an opportunity for LIBER library professionals working within national, research, university to cultural heritage institutions, to not only support digital scholars on increasingly more complex computationally driven research, but also to apply such methods in the care and curation of heritage collections, capacity building in digital scholarship methods, including data science, was unevenly distributed across this community however.\nThough training for the sector around the use of data science and computational methods in the library context has grown considerably within the last decade, fifty-eight percent of LIBER Member respondents still noted as recently as 2019 ‘technical knowledge - such as coding or tool expertise’ as the primary deficit in their environments in Europe’s Digital Humanities Landscape: A Study From LIBER’s Digital Humanities & Digital Cultural Heritage Working Group.\nThe provision of these valuable resources remains fragmented online and across institutions at a local, national and international level. This leads to considerable inefficiency and inconsistent skills acquisition across LIBER member institutions and sustains an imbalance between the wide-spread ambitions of scholars to undertake computational research with library and heritage collections, and a paucity of institutions with capacity to enable these. Equally, it impedes research libraries and cultural institutions from benefiting from the digital transformations computational methods can offer."
  },
  {
    "objectID": "project-overview.html#core-project-team",
    "href": "project-overview.html#core-project-team",
    "title": "About",
    "section": "Core Project Team",
    "text": "Core Project Team\nThe site and content are maintained by the Co-Chairs and select Members of the collaborating WGs listed here who act as the core project delivery team and editors of this resource.\nNora McGregor, Managing Editor & Site Maintainer DSDCH\nJodie Double, Editor DSDCH\nPéter Király, Editor DSLib\nPeter Verhaar, Editor DSLib"
  },
  {
    "objectID": "project-overview.html#community-contributors",
    "href": "project-overview.html#community-contributors",
    "title": "About",
    "section": "Community Contributors",
    "text": "Community Contributors\nEach Topic Guide is written by specific named contributors but we also welcome changes and contributions to this resource via logging issues or if you’re a more seasoned GitHub user, via pull requests to the github repository.\nThe project team would like to thank all of our LIBER working group members and others who have contributed to this resource and supported our endeavours here, in particular: Adi Keinan-Schoonbaert, Alex Fenlon, Andy Corrigan, Annika Lindh, Corine Deliot, Cosima Wagner, Eleonora Gandolfi, Greete Veesalu, Gustavo Candela, Harry Lloyd, Ilkay Holt, Jez Cope, Jodie Double, Liam Green-Hughes, Liam O’Dwyer, Maria Rehbinder, Mia Ridge, Neha Moopen, Niamh Malin, Nora McGregor, Péter Király, Peter Verhaar, Sofie Wennström, Stephen McGregor, Valentina Vavassori."
  },
  {
    "objectID": "project-overview.html#acknowledgements",
    "href": "project-overview.html#acknowledgements",
    "title": "About",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nWe have taken great inspiration from other incredible training initiatives such as the British Library Digital Scholarship Training Programme, DH Literacy Guidebook and The Programming Historian in the development of this resource and thank those projects for paving the way!"
  },
  {
    "objectID": "project-overview.html#contact-us",
    "href": "project-overview.html#contact-us",
    "title": "About",
    "section": "Contact us",
    "text": "Contact us\nIf you’d like to ask a question of the project team you can please send an email to Nora McGregor, nora.mcgregor@bl.uk or any of Co-Chairs and select Members of the collaborating WGs listed here who act as the core project delivery team and editors of this resource."
  },
  {
    "objectID": "04-digitalmapping.html",
    "href": "04-digitalmapping.html",
    "title": "Digital Mapping",
    "section": "",
    "text": "Cultural Heritage collections are full of object stories. Objects move through time and space and encounter multiple people and other objects. Additionally, as explained in the guide on data visualisation, humans are better able to see and interpret data based on visualising them with colours and shapes.\nWhen we combine these two concepts, it is therefore not surprising that one of the most common visualisations for cultural heritage collections, and library collections specifically, are maps.\nHowever, creating a map or adding objects on a map are not neutral processes: maps reproduce ways of seeing, giving specific interpretations of the world. For example, a map created according to a Mercator projection (created by Gerardus Mercator in 1569) will expand the lands above the Equator, therefore making Madagascar as big as Great Britain while it is actually twice the size. This projection reflects a view of the world that is western-centric. Despite criticism, this projection is actually the base of Web Mercator.\nWeb Mercator is a de facto standard for Web Mapping and it is used by Google Maps, Bing Maps and OpenStreetMap, therefore continuing the reinforcement of the same way of seeing the world while hiding the fact that it is a way of seeing the world.\nRecognising that every map is not neutral and it is instead a cultural artefact is particularly important when approaching the digital mapping of collections as the maps may enhance their partiality.\nAt the same time, using maps as a visualisation tool has the potential both to make libraries aware of new and unheard stories within their collections, to connect collections from multiple institutions (see for example Heritage for All) and to identify gaps that may be worth exploring.\nBecause of their ubiquity, they have the potential to be easy to explore for different audiences, keeping in mind that accessibility and usability, as much as with other visualisations and interfaces, need to be kept at the centre of their development.\nKnowing who will use the maps and for what purpose is therefore essential as much as being aware of the interpretation that the map is proposing and how this interpretation is influenced by the adoption of a specific technology and how the process of mapping happened.\nFor example, visualising indigenous knowledge in a Web Mercator-based application may be problematic as the approach to place and its visualisation may be different than the one presented on some platforms and may require a discussion with communities on how to best represent their interpretation of place and their culture.\nTo digitally map collections, there are a few options available in terms of tools and softwares:\n\nFirst of all, there are specialistic software available such as QGIS and ArcGIS where geolocated data (that is data that have coordinates) can be visualised on maps chosen by the librarian/researcher and historical maps can be associated with coordinates.\nIt is possible to visualise geolocated data on online platforms designed for digital mapping that are not specifically for the Humanities, such as Google Maps.\nThere are online tools designed to visualise humanities data in multiple ways and have an option of visualising data on a map such as Recogito, where annotated places on a text can be visualised, or Palladio that is used to visualise data as networks.\nThere are generic visualisation tools such as Tableau, that has been explored in the data visualisation guide.\nFinally, it is worth mentioning the work the IIIF community in standardising the georeferencing of maps in IIIF and creating geospatial annotations.",
    "crumbs": [
      "Entrance",
      "Digital Mapping"
    ]
  },
  {
    "objectID": "04-digitalmapping.html#introduction",
    "href": "04-digitalmapping.html#introduction",
    "title": "Digital Mapping",
    "section": "",
    "text": "Cultural Heritage collections are full of object stories. Objects move through time and space and encounter multiple people and other objects. Additionally, as explained in the guide on data visualisation, humans are better able to see and interpret data based on visualising them with colours and shapes.\nWhen we combine these two concepts, it is therefore not surprising that one of the most common visualisations for cultural heritage collections, and library collections specifically, are maps.\nHowever, creating a map or adding objects on a map are not neutral processes: maps reproduce ways of seeing, giving specific interpretations of the world. For example, a map created according to a Mercator projection (created by Gerardus Mercator in 1569) will expand the lands above the Equator, therefore making Madagascar as big as Great Britain while it is actually twice the size. This projection reflects a view of the world that is western-centric. Despite criticism, this projection is actually the base of Web Mercator.\nWeb Mercator is a de facto standard for Web Mapping and it is used by Google Maps, Bing Maps and OpenStreetMap, therefore continuing the reinforcement of the same way of seeing the world while hiding the fact that it is a way of seeing the world.\nRecognising that every map is not neutral and it is instead a cultural artefact is particularly important when approaching the digital mapping of collections as the maps may enhance their partiality.\nAt the same time, using maps as a visualisation tool has the potential both to make libraries aware of new and unheard stories within their collections, to connect collections from multiple institutions (see for example Heritage for All) and to identify gaps that may be worth exploring.\nBecause of their ubiquity, they have the potential to be easy to explore for different audiences, keeping in mind that accessibility and usability, as much as with other visualisations and interfaces, need to be kept at the centre of their development.\nKnowing who will use the maps and for what purpose is therefore essential as much as being aware of the interpretation that the map is proposing and how this interpretation is influenced by the adoption of a specific technology and how the process of mapping happened.\nFor example, visualising indigenous knowledge in a Web Mercator-based application may be problematic as the approach to place and its visualisation may be different than the one presented on some platforms and may require a discussion with communities on how to best represent their interpretation of place and their culture.\nTo digitally map collections, there are a few options available in terms of tools and softwares:\n\nFirst of all, there are specialistic software available such as QGIS and ArcGIS where geolocated data (that is data that have coordinates) can be visualised on maps chosen by the librarian/researcher and historical maps can be associated with coordinates.\nIt is possible to visualise geolocated data on online platforms designed for digital mapping that are not specifically for the Humanities, such as Google Maps.\nThere are online tools designed to visualise humanities data in multiple ways and have an option of visualising data on a map such as Recogito, where annotated places on a text can be visualised, or Palladio that is used to visualise data as networks.\nThere are generic visualisation tools such as Tableau, that has been explored in the data visualisation guide.\nFinally, it is worth mentioning the work the IIIF community in standardising the georeferencing of maps in IIIF and creating geospatial annotations.",
    "crumbs": [
      "Entrance",
      "Digital Mapping"
    ]
  },
  {
    "objectID": "04-digitalmapping.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "04-digitalmapping.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "Digital Mapping",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)\nHaving introduced the importance of maps to visualise people, objects and relationships in cultural heritage, it is not surprising that digital mapping provides multiple potential applications and challenges for libraries. Maps can be used, as I said before, to communicate an interpretation with audiences, to let them explore collections or to analyse their collections as data, to see gaps and uncover stories.\nFor example, the project Mapping the Republic of Letters by Stanford University has used maps to visualise and let users explore the places where editions of Voltaire were published between 1712 and 1800 or to visualise the places tourists explored during the Grand Tour.\nIf the previous example illustrates how geolocated data can help study editions and letters and see the bigger picture, maps can also be used to let users explore collections, as mentioned before with Heritage for All. An example is WarSampo that lets users explore the relevant places, events, people and photographs linked to Finland during World War II using Linked Open Data, or the Holocaust refugee map developed by The Weiner Holocaust Library that includes not only documents and photographs but also recorded interviews.\nFinally, digital mapping can be used for digital storytelling, narrating stories related to places such as with Curiocity by the National Library of Singapore. The library has curated, along with the National Archives, stories related to places in Singapore, mixing maps and photographs to explore their past and present cultural significance.",
    "crumbs": [
      "Entrance",
      "Digital Mapping"
    ]
  },
  {
    "objectID": "04-digitalmapping.html#hands-on-activityself-guided-tutorials",
    "href": "04-digitalmapping.html#hands-on-activityself-guided-tutorials",
    "title": "Digital Mapping",
    "section": "Hands-on activity/self-guided tutorial(s)",
    "text": "Hands-on activity/self-guided tutorial(s)\nHere are some helpful tools that can be used to begin digital mapping. They are divided by typology: web-based, software, and coding-based. Some are designed specifically for humanities and cultural heritage collections data while others are designed for more generic geospatial data. Most have great documentation and tutorials available.\n\nWeb-based tools\n\nPalladio is useful for testing multiple visualisations with Humanities data. It offers the option to upload .csv files, structure them and visualise them in maps, timelines and networks. There are a few tutorials for beginners available here.\nRecogito is a platform for annotating text. It is also possible to apply Name Entity Recognition, disambiguate places and visualise them on the map feature provided (see this 10 minute tutorial).\nGoogle Maps allows saving and sharing places and trails. It is also possible to create, customise and share maps through My Maps. To understand how it works and how it differs from Google Earth Pro, there is a tutorial on Programming Historian.\nAllMaps is designed to visualise and georeference maps in IIIF.\n\n\n\nSoftware\n\nArcGIS is probably the most well-known Geographic Information System (GIS) software, providing enhanced capabilities compared to the previous web-based options, including spatial data analysis. It is a commercial tool which offers a range of products, from desktop software to cloud-based platforms. For a brief introduction to GIS and its basic components,this course by the MIT is particularly handy. There are a few beginner tutorials in the documentation provided by Esri.\nQGIS is an open-source and free software that offers some of the capabilities of ArcGIS. There are beginner tutorials on Programming Historian on installing it and creating layers and a comprehensive documentation on the official website.\nGoogle Earth Pro is a free software based on Google Earth but offers enhanced capabilities for handling geospatial data and performing some basic data analysis (for the difference with Google Maps see here)\n\n\n\nCoding\nThere are multiple libraries for digital mapping, depending on the programming language used.\n\nFor Python, geopandas, basemap and matplotlib are good for static maps, while Folium, Plotly, Dash (for dashboards) and ipyleaflet are used to create interactive maps in Python and in Jupyter Notebooks.\nFor R, for static maps there is ggplot while, for interactive maps, leaflet is a good option.\nFinally, it is worth mentioning the D3 Javascript Library that is specifically designed for data visualisation and includes a lot of coded examples of maps.\n\n\n\nAdditional tutorials\n\nQGIS and ArcGIS\n\nClifford, J., MacFadyen, J., & Macfarlane, D. (2013). Georeferencing in QGIS 2.0. Programming Historian, 2. https://doi.org/10.46430/phen0027\nColson, J. (2017). Geocoding historical data using QGIS. Programming Historian, 6. https://doi.org/10.46430/phen0066\nGeospatial Historian. (n.d.) Lessons. Retrieved January 22 2025.Lessons – Geospatial Historian\n\n\n\nProgramming in Python and R\n\nPham, K. (2017). Web mapping with Python and Leaflet. Programming Historian, 6. https://doi.org/10.46430/phen0070\nRyan, Y. (2022). Making an interactive web application with R and Shiny. Programming Historian, 11. https://doi.org/10.46430/phen0105",
    "crumbs": [
      "Entrance",
      "Digital Mapping"
    ]
  },
  {
    "objectID": "04-digitalmapping.html#recommended-readingviewing",
    "href": "04-digitalmapping.html#recommended-readingviewing",
    "title": "Digital Mapping",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing\nThere are a few additional readings that may be interesting to get more information or to explore additional options for digital mapping.\n\nOther library guides on digital mapping and GIS\n\nNYU Libraries. (n.d.). Mapping and timelines. Retrieved January 21, 2025, from https://guides.nyu.edu/digital-humanities/tools-and-software/mapping-and-timelines\nUC Berkeley Library. (n.d.). Digital mapping. Retrieved January 21, 2025, from https://guides.lib.berkeley.edu/dh/mapping#s-lg-box-33113349\nUBC Library. (n.d.). Getting started with GIS. Retrieved January 21, 2025, from https://guides.library.ubc.ca/gis/gettingstarted\nUniversity of Reading Library. (n.d.). Digital maps. Retrieved January 21, 2025, from https://libguides.reading.ac.uk/maps/digitalmaps",
    "crumbs": [
      "Entrance",
      "Digital Mapping"
    ]
  },
  {
    "objectID": "04-digitalmapping.html#finding-communities-of-practice",
    "href": "04-digitalmapping.html#finding-communities-of-practice",
    "title": "Digital Mapping",
    "section": "Finding Communities of Practice",
    "text": "Finding Communities of Practice\nIf you are interested in knowing more about digital mapping, there are a few communities of practice, conferences and summer schools that you may be interested to attend.\n\nThe Spatial Humanities Conference is held annually and it is specialised in geospatial technologies, geodata and the Humanities.\nThe GeoHumanities community is a special interest group part of the ADHO (Alliance of Digital Humanities Organisations).\nIIIF has an active community working on creating standards for mapping.\nThe Digital Humanities Oxford Summer School offers multiple DH courses, both theoretical and practical. Humanities Data is a good introduction to Humanities data processing and it usually includes some coursework on GIS. If there is an interest in data visualisation and programming at a more advanced level, there is a course specialised on Applied Data Analysis that explores, among others, geomapping.\nThe Cultural Heritage Data School by the University of Cambridge is dedicated to exploring cultural heritage data using digital methods and approaches. The programme changes every year and may include lectures on digital mapping.",
    "crumbs": [
      "Entrance",
      "Digital Mapping"
    ]
  },
  {
    "objectID": "05-digitisation.html",
    "href": "05-digitisation.html",
    "title": "Digitisation: Imaging, 3D and RTI",
    "section": "",
    "text": "Over recent decades research library collections, operations, and audiences have moved from a largely analogue to a mixed analogue/digital environment. So, it will come as no surprise that advances in digital imaging have put digitisation in the position of being one of the most prominent demonstrations of this digital shift. Cultural heritage institutions of all sizes are likely to have some level of digitisation and imaging workflows and standards in place, either through in-house imaging labs or outsourcing through mass digitisation projects like Google Books to keep up with this shift. Many seek to take advantage of uniqueness in their collection by exploiting advanced imaging methods such as 3D modelling, Multispectral Imaging and Reflectance Transformation Imaging (RTI).\nOf course, now that almost everyone has a camera available to them via their phone, it may appear easy for anyone to digitise collection items quickly, or even make their own 3D model, but navigating this complex landscape of technologies, terminologies, methodologies, gadgets and gizmos can be quite daunting for anyone. Those working in cultural heritage institutions also need to consider not just how the technologies work, but how they can be employed within budget, integrated at scale into larger workflows, support preservation alongside access, and be deployed sensitively. This guide aims to help library professionals to understand some of the questions and considerations they need to keep in mind while exploring and having a play with some of these new advanced imaging methods for collection digitisation.\n\n\nIdentifying the right imaging method for different objects, and then the specific technology or combination of them to use can be confusing, and is often restricted by what resources you might have available. Knowing and understanding why you are digitising something from the outset, and what it will be used for, will also inform the decision process, so spend some time thinking about that - the wrong choices can be costly and time consuming. That said, in my experience many of the technologies advance so quickly that whatever you choose, no matter how thoughtfully, will likely be out of date by the time you’ve finished - so my advice is to accept this inevitably, don’t let it stop you, start with a sound approach, do the best with what you can, and know who, and when, to ask for advice!\nHere are brief introductions to some of the advanced imaging methods we have at our disposal:\n\n\n\nMost imaging methods build on a foundation of high quality 2D imaging. You’ll have heard phone manufacturers boasting about how many megapixels their camera has. But this isn’t always an indicator of quality, there are lots of other factors, the more important factor being the size and quality of the imaging sensor. So while using your phone camera may seem a cost-effective and easy solution for digitising collection items, it is unlikely to provide the high-resolution and preservation quality you’re after long term. The guide ‘Remote Capture: Digitising Documentary Heritage in Challenging Locations’ explains this quite well in their chapter on Equipment and skills for digitising in the field. You can see some great examples that demonstrate why high-quality imaging is a must in my case-study.\n\n\n\nAn illustration showing example digital image sensor sizes.\n\n\n\n\n\n3D data can be generated through different methods and technologies. These include photogrammetry, which uses images to obtain accurate measurable information of real-world objects and the terrain, and LIDAR which stands for ‘light detection and ranging’ and is a remote sensing method that uses pulses of light to measure distances and angles as they bounce back into the sensor. The data produced from these methods can then be used to build 3D models of objects or the terrain. 3D models help a user build an understanding of the form of an object, and can even be useful in conveying book construction for example. It works well on most objects, but can run into difficulties with reflective materials like polished glass and metal. Check out some examples in the case-study.\n3D models of cultural heritage objects can then be used in AR/VR/XR environments. You might have come across all three of these terms and been slightly confused as to what the difference is. Augmented reality (AR) is an experience where reality is enhanced in some way using technology. Virtual reality (VR) is usually an entirely simulated experience in which you are immersed. Extended reality (XR) is an umbrella term that encompasses AR, VR or even mixed reality (MR), in which both actual and virtual worlds are merged.\n\n\n\nThis is a method of examining an object under different wavelengths of light – you’ve probably heard of infrared and ultraviolet, but there’s a huge spectrum that can be applied in order to reveal underwriting or investigate faded text and even the structure of the medium, revealing things like paper manufacturing watermarks. Whilst multispectral images can be hard for the average user to interpret, specialists can use them to transcribe long lost texts. For an example of this, you can see a recently rediscovered Merlin Fragment in the IIIF viewer below, or check out the digital edition of the Codex Zacynthius.\n\n\n\n\n\nReflectance Transformation Imaging (RTI) is a technique that creates hyper-real digital images with which the viewer can interact. It creates texture mapping by capturing multiple images of the subject from a fixed point whilst the light source varies in position. This is really useful for revealing the textured detail in surfaces of objects such as coins, engravings or pressed plant material - there are some examples of a herbarium sheet in my case-study. This diagram shows a basic RTI set-up, you can learn more about the technique and process from the Cultural Heritage Imaging’s website about RTI.\n\n\n\nAn illustration showing an example RTI setup, by Andy Corrigan.\n\n\n\n\n\n\nLighting is often as important, if not more so, than the camera you are using, so it pays to learn a bit about that too. For example, a camera sensor is more sensitive to colour temperature and contrast than the human eye. The guide Remote Capture: Digitising Documentary Heritage in Challenging Locations explains a bit more in their section about lighting and flash.\n\nEthics & Cultural Sensitivities Another thing to remember when selecting and preparing to digitise collections is the impact of our own narrative into the process. What we choose to select, our interactions, and the choices we make for providing access to objects, become entwined and embedded through the process of digitisation, and this should be thought through as well. The Digital Preservation Coalition has published a useful guidance note ‘Exploring ethical considerations for providing access to digital heritage collections’, and there is also some interesting discussion in Fafinski’s article ‘Facsimile narratives: Researching the past in the age of digital reproduction’.\nFacsimile, surrogate, object or edition? Opinions often vary on how/what we consider digitised objects to be and what we call them. You may have come across the terms “digital surrogate”, “digital facsimile” or “digital edition” for example. The digitisation process can remove or reduce some aspects, but can add or increase others. Due to this, the outputs of digitisation are now more widely considered to constitute a distinct thing from their real-world original.\nCopyright and licensing is a complex issue, but an essential consideration when digitising anything. You might want to start by looking at the LIBER DS Topic Guide on Copyright.\nHosting Your institution might have one or more hosting solutions on which you can store your digitisation and make it available over the web and integrate it into existing systems. If not, then IIIF might be worth exploring, and a great place to start is the LIBER DS Topic Guide on IIIF. But whilst regular image hosting options are common, more complex digital objects can be a challenge. If you are creating 3D models, RTI or other specialist imaging, you will need to consider a number of options. Many cultural institutions have been hosting their 3D models through a platform called Sketchfab, but at the time of writing, the platform has recently been absorbed into a bigger platform, and its future is in doubt, providing a good example of how challenging it can be relying on third party services. Other options to consider include MorphoSource, a data repository that is more focussed on research and academia, or tools such as Model-Viewer and A-Frame that can be used to build your own virtual experiences. The IIIF community are currently working on support for 3D objects, so keep an eye on developments there!\n\nDigital Preservation is also important to consider - digitisation can be expensive, so don’t risk losing your valuable assets. A great place to start is the Digital Preservation Coalition.",
    "crumbs": [
      "Entrance",
      "Digitisation: Imaging, 3D and RTI"
    ]
  },
  {
    "objectID": "05-digitisation.html#introduction",
    "href": "05-digitisation.html#introduction",
    "title": "Digitisation: Imaging, 3D and RTI",
    "section": "",
    "text": "Over recent decades research library collections, operations, and audiences have moved from a largely analogue to a mixed analogue/digital environment. So, it will come as no surprise that advances in digital imaging have put digitisation in the position of being one of the most prominent demonstrations of this digital shift. Cultural heritage institutions of all sizes are likely to have some level of digitisation and imaging workflows and standards in place, either through in-house imaging labs or outsourcing through mass digitisation projects like Google Books to keep up with this shift. Many seek to take advantage of uniqueness in their collection by exploiting advanced imaging methods such as 3D modelling, Multispectral Imaging and Reflectance Transformation Imaging (RTI).\nOf course, now that almost everyone has a camera available to them via their phone, it may appear easy for anyone to digitise collection items quickly, or even make their own 3D model, but navigating this complex landscape of technologies, terminologies, methodologies, gadgets and gizmos can be quite daunting for anyone. Those working in cultural heritage institutions also need to consider not just how the technologies work, but how they can be employed within budget, integrated at scale into larger workflows, support preservation alongside access, and be deployed sensitively. This guide aims to help library professionals to understand some of the questions and considerations they need to keep in mind while exploring and having a play with some of these new advanced imaging methods for collection digitisation.\n\n\nIdentifying the right imaging method for different objects, and then the specific technology or combination of them to use can be confusing, and is often restricted by what resources you might have available. Knowing and understanding why you are digitising something from the outset, and what it will be used for, will also inform the decision process, so spend some time thinking about that - the wrong choices can be costly and time consuming. That said, in my experience many of the technologies advance so quickly that whatever you choose, no matter how thoughtfully, will likely be out of date by the time you’ve finished - so my advice is to accept this inevitably, don’t let it stop you, start with a sound approach, do the best with what you can, and know who, and when, to ask for advice!\nHere are brief introductions to some of the advanced imaging methods we have at our disposal:\n\n\n\nMost imaging methods build on a foundation of high quality 2D imaging. You’ll have heard phone manufacturers boasting about how many megapixels their camera has. But this isn’t always an indicator of quality, there are lots of other factors, the more important factor being the size and quality of the imaging sensor. So while using your phone camera may seem a cost-effective and easy solution for digitising collection items, it is unlikely to provide the high-resolution and preservation quality you’re after long term. The guide ‘Remote Capture: Digitising Documentary Heritage in Challenging Locations’ explains this quite well in their chapter on Equipment and skills for digitising in the field. You can see some great examples that demonstrate why high-quality imaging is a must in my case-study.\n\n\n\nAn illustration showing example digital image sensor sizes.\n\n\n\n\n\n3D data can be generated through different methods and technologies. These include photogrammetry, which uses images to obtain accurate measurable information of real-world objects and the terrain, and LIDAR which stands for ‘light detection and ranging’ and is a remote sensing method that uses pulses of light to measure distances and angles as they bounce back into the sensor. The data produced from these methods can then be used to build 3D models of objects or the terrain. 3D models help a user build an understanding of the form of an object, and can even be useful in conveying book construction for example. It works well on most objects, but can run into difficulties with reflective materials like polished glass and metal. Check out some examples in the case-study.\n3D models of cultural heritage objects can then be used in AR/VR/XR environments. You might have come across all three of these terms and been slightly confused as to what the difference is. Augmented reality (AR) is an experience where reality is enhanced in some way using technology. Virtual reality (VR) is usually an entirely simulated experience in which you are immersed. Extended reality (XR) is an umbrella term that encompasses AR, VR or even mixed reality (MR), in which both actual and virtual worlds are merged.\n\n\n\nThis is a method of examining an object under different wavelengths of light – you’ve probably heard of infrared and ultraviolet, but there’s a huge spectrum that can be applied in order to reveal underwriting or investigate faded text and even the structure of the medium, revealing things like paper manufacturing watermarks. Whilst multispectral images can be hard for the average user to interpret, specialists can use them to transcribe long lost texts. For an example of this, you can see a recently rediscovered Merlin Fragment in the IIIF viewer below, or check out the digital edition of the Codex Zacynthius.\n\n\n\n\n\nReflectance Transformation Imaging (RTI) is a technique that creates hyper-real digital images with which the viewer can interact. It creates texture mapping by capturing multiple images of the subject from a fixed point whilst the light source varies in position. This is really useful for revealing the textured detail in surfaces of objects such as coins, engravings or pressed plant material - there are some examples of a herbarium sheet in my case-study. This diagram shows a basic RTI set-up, you can learn more about the technique and process from the Cultural Heritage Imaging’s website about RTI.\n\n\n\nAn illustration showing an example RTI setup, by Andy Corrigan.\n\n\n\n\n\n\nLighting is often as important, if not more so, than the camera you are using, so it pays to learn a bit about that too. For example, a camera sensor is more sensitive to colour temperature and contrast than the human eye. The guide Remote Capture: Digitising Documentary Heritage in Challenging Locations explains a bit more in their section about lighting and flash.\n\nEthics & Cultural Sensitivities Another thing to remember when selecting and preparing to digitise collections is the impact of our own narrative into the process. What we choose to select, our interactions, and the choices we make for providing access to objects, become entwined and embedded through the process of digitisation, and this should be thought through as well. The Digital Preservation Coalition has published a useful guidance note ‘Exploring ethical considerations for providing access to digital heritage collections’, and there is also some interesting discussion in Fafinski’s article ‘Facsimile narratives: Researching the past in the age of digital reproduction’.\nFacsimile, surrogate, object or edition? Opinions often vary on how/what we consider digitised objects to be and what we call them. You may have come across the terms “digital surrogate”, “digital facsimile” or “digital edition” for example. The digitisation process can remove or reduce some aspects, but can add or increase others. Due to this, the outputs of digitisation are now more widely considered to constitute a distinct thing from their real-world original.\nCopyright and licensing is a complex issue, but an essential consideration when digitising anything. You might want to start by looking at the LIBER DS Topic Guide on Copyright.\nHosting Your institution might have one or more hosting solutions on which you can store your digitisation and make it available over the web and integrate it into existing systems. If not, then IIIF might be worth exploring, and a great place to start is the LIBER DS Topic Guide on IIIF. But whilst regular image hosting options are common, more complex digital objects can be a challenge. If you are creating 3D models, RTI or other specialist imaging, you will need to consider a number of options. Many cultural institutions have been hosting their 3D models through a platform called Sketchfab, but at the time of writing, the platform has recently been absorbed into a bigger platform, and its future is in doubt, providing a good example of how challenging it can be relying on third party services. Other options to consider include MorphoSource, a data repository that is more focussed on research and academia, or tools such as Model-Viewer and A-Frame that can be used to build your own virtual experiences. The IIIF community are currently working on support for 3D objects, so keep an eye on developments there!\n\nDigital Preservation is also important to consider - digitisation can be expensive, so don’t risk losing your valuable assets. A great place to start is the Digital Preservation Coalition.",
    "crumbs": [
      "Entrance",
      "Digitisation: Imaging, 3D and RTI"
    ]
  },
  {
    "objectID": "05-digitisation.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "05-digitisation.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "Digitisation: Imaging, 3D and RTI",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)\nOne of the biggest benefits to digitising content is often thought of as one of access. Sharing things that have been locked away in our libraries and archives, sometimes for many hundreds of years, to anyone, anywhere in the world with an internet connection is a very powerful thing. This isn’t the only reason or advantage to digitisation - some might be surprising or even more compelling.\nAcknowledgment that the act of digitisation is also an important and valuable part of the research process is steadily growing. For example, over the last few years in the UK, recognition amongst university and research institutions of initiatives such as the Technician Commitment and the Hidden Ref has been increasingly impactful.\n\nCambridge University Library\nBy way of a case study, I wanted to share some stories relating to digitisation here at Cambridge Digital Library. Hopefully these demonstrate just some of the potential and value of digitisation.\nWe are lucky here at Cambridge that a long history of larger scale digitisation projects means we have been able to steadily increase the amount of equipment, skills, and experience we have and the services we can offer researchers. But this activity is more than a service, we work in direct collaboration with researchers, curators, conservators, publishers and exhibitions teams to help them achieve the results they need.\n\n\nFlat digitisation\nAt Cambridge, our focus is very much on delivering the highest possible quality results we can. This is good practice when thinking about the longevity of your outputs, digital preservations needs thinking about at every stage of course, but a major advantage of this approach is that the higher quality the result, the more likely you are to make new discoveries and learn new things about the objects in our care. We have many examples of things that have only been spotted because of the high quality imaging we produce. Take a look at some of the Benefits of Digitisation in this interactive story:\n\n\n\n\n3D and other multidimensional media\nWhilst we might normally expect the written word to occur on a page, the world is more complex than that and even paper isn’t as “flat” as you might expect. Some of the most ancient texts in our collections are Oracle Bones, that are about 3000 years old. They are objects that have undergone a process far more complex than simply marking a flat surface with a pen. They’re materiality is intrinsic to the meaning of the text on their surfaces. But even though something this ancient has been studied for hundreds of years, they are so fragile that most studies are undertaken from impressions of the text (a process which flattens the text for reading and reproduction on the printed page), so it is not often the object is taken out of its carefully constructed archival housing. It was not until the curator saw the 3D model of this oracle bone in the video below, that they noticed there was a surface of it on which there were markings that had never been spotted before!\n\n\nSo, as we can see, 3D modelling can facilitate deeper study and reduce the need to handle fragile objects. But 3D printing them can also be a great way to bring collections to life and enable increased handling via replicas. This is a great way to engage anyone with handling collection items, but can be a particularly pertinent way to bring them to life for people with visual impairments, as we can see in The tale of the ‘Old Horse’ for example:\n\n\nBut 3D models don’t work for everything. In another project we have been collaborating across the other collections at the University of Cambridge to experiment with digitally re-uniting the wide variety of collections relating to Charles Darwin that the University has split over various museums and archives. One particular challenge with this project was presented in the form of herbarium sheets. Plant specimens that Darwin collected on the Beagle Voyage, some of which are now extinct. Whilst the writing on the sheets is well captured by a flat digital image, the plant parts themselves have form and texture, an understanding of which cannot be perceived so well on a flatly lit image. We experimented with 3D modelling them, but ironically they are too flat – the processes involved in 3D modelling didn’t cope well with the flat paper surfaces. Whilst it would be possible to rectify this digitally, it would take a great deal of time, rendering the process extremely inefficient. So we are experimenting with RTI, which allows us to capture texture in a much more engaging way.\nViewing RTI files currently requires specific software, although developments are underway to facilitate the experience through a web browser. The video below demonstrates a few examples that showcase what the experience is like:\n\n\nYou might even find that occasionally people want to see inside something! CT Scanning certainly isn’t an everyday technique that we might associate with research libraries, but you never know. The CT scan shown in the video below is of a fish specimen collected by Charles Darwin on the Beagle Voyage nearly 200 years ago. Preserved in alcohol in a jar, it’s not very easy to inspect or study the real thing:",
    "crumbs": [
      "Entrance",
      "Digitisation: Imaging, 3D and RTI"
    ]
  },
  {
    "objectID": "05-digitisation.html#hands-on-activityself-guided-tutorials",
    "href": "05-digitisation.html#hands-on-activityself-guided-tutorials",
    "title": "Digitisation: Imaging, 3D and RTI",
    "section": "Hands-on activity/self-guided tutorial(s)",
    "text": "Hands-on activity/self-guided tutorial(s)\nIf you’ve got half an hour and a colleague or friend to spare, why not take your first steps into a virtual world and have a go at making a 3D model.\nThe “Big Me, Little Me” exercise has been developed by the team at StoryFutures, and is a great way to start thinking about 3D modelling and the virtual world it creates.\n\n!Warning! - You’ll probably end up wanting to spend longer!\n:-) The question you always need to ask yourself though, is should you?\n\n\nStep 1: Download the Scaniverse App to your mobile device.\n\nStep 2: Scan your friend or colleague. Here are some tips:\n\nMove slowly and as steadily as possible - it also helps if your subject is comfortable and can stay as still as possible.\n\nTry to follow a regular pattern as you move around your subject. Moving in a spiral shape around them from top to bottom can work well.\n\nPay extra attention to heads and faces - avoid starting or stopping with the face as this can result in a visible ‘seam’.\n\n\nStep 3: Process your scan - this might take a few minutes, maybe have a cup of tea.\n\nStep 4: Once your scan is processed, click the “AR View” button. This allows you to play around with the scan in augmented reality, so you can adjust the scale and position. This is the fun bit - you can shrink the scan and get your colleague to adopt a funny pose with a mini version of themselves!\n\nStep 5: Now you can take a screenshot and send it round the team to make everyone smile!",
    "crumbs": [
      "Entrance",
      "Digitisation: Imaging, 3D and RTI"
    ]
  },
  {
    "objectID": "05-digitisation.html#recommended-readingviewing",
    "href": "05-digitisation.html#recommended-readingviewing",
    "title": "Digitisation: Imaging, 3D and RTI",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing\nThere’s loads out there to read-up on that covers everything from the very technical aspects and guidance to the more philosophical side of things - inspiration is everywhere and creative approaches have a habit of seeding into fruitful outcomes!\n\nMaterial Awareness : Exploring the Entanglement of Library Digitization and Digital Textual Scholarship. Martinez, Merisa. (2024). PhD dissertation. Högskolan i Borås.\n\nWhy Do We Digitize? The Case for Slow Digitization. Prescott, Andrew and Hughes, Lorna. (2018). Archive Journal.\n\nA Field Guide to Digital Surrogates: Evaluating and Contextualizing a Rapidly Changing Resource. Stanford, Emma. (2020). In Kathryn Brown (ed.) ‘The Routledge Companion to Digital Humanities and Art History’ (1st ed.). Routledge. Pp 203-214.\n\nDigital humanities and digitised cultural heritage. Terras, Melissa. (2022). In J O’Sullivan (ed.), ‘The Bloomsbury Handbook to the Digital Humanities’ (1st ed.). Bloomsbury Handbooks, Bloomsbury Academic. pp. 255-266.\n\nFacsimile narratives: Researching the past in the age of digital reproduction. Fafinski, Mateusz. (2021). In ‘Digital Scholarship in the Humanities’, Vol. 37. No. 1, 2022.\n\nTechnical Guidance:\n\nRemote Capture: Digitising Documentary Heritage in Challenging Locations. Edited by Jody Butterworth, Andrew Pearson, Patrick Sutherland & Adam Farquhar. (2018). Open Book Publishers.\n\nReflectance Transformation Imaging (RTI). Cultural Heritage Imaging.\n\nFrom Shelf to Europeana: Digitization Workflow Handbook. Europeana.\n\nBasic principles and tips for 3D digitisation of cultural heritage. Europeana (2020).\n\nLearning hub. Association for Historical & Fine Art Photography (AHFAP).\n\nManual for the photography of 3D objects. Rijksmuseum (2017).\n\nTechnical Guidelines for Digitizing Cultural Heritage Materials (3rd ed.). Federal Agencies Digital Guidelines Initiative (FADGI), (2023).\n\nThe London Charter: For the Computer-Based Visualisation of Cultural Heritage. (2009).\nHighlight-Reflectance Transformation Imaging (H-RTI) for Cultural Heritage. Historic England (2018).",
    "crumbs": [
      "Entrance",
      "Digitisation: Imaging, 3D and RTI"
    ]
  },
  {
    "objectID": "05-digitisation.html#finding-communities-of-practice",
    "href": "05-digitisation.html#finding-communities-of-practice",
    "title": "Digitisation: Imaging, 3D and RTI",
    "section": "Finding Communities of Practice",
    "text": "Finding Communities of Practice\nAs we all know, libraries are friendly places and often keen on collaborating. Why not reach out to some libraries with digitisation studios and see if you can go and visit them to learn a bit more about how they operate or what equipment they’re using first hand - it can really help to see a variety of different set-ups in person to start building up an idea of what might work for you. Or try and find a local workshop or summer school to attend that will give you some hands-on experience and the opportunity to meet others like you!",
    "crumbs": [
      "Entrance",
      "Digitisation: Imaging, 3D and RTI"
    ]
  },
  {
    "objectID": "03-dataviz.html",
    "href": "03-dataviz.html",
    "title": "Data Visualisation",
    "section": "",
    "text": "Why do we visualise data? For data to tell us something we need to look for patterns, and we are much better at finding these patterns in colours and shapes than in a table of raw data. Visualisations are key to developing the story we want to tell with our data.\nWhen do we visualise data? There are two main moments when working with data that we need to visualise it. First, in the exploratory phase, when we are trying to understand the data, to get insights that lead to fruitful lines of enquiry. These visualisations are rough and ready, meant for us or at most a select few around us to generate debate about what information the data might contain.\nSecond, in the explanatory phase, when we have understood the data and move on to insightful analyses that generate new understanding. These visualisations communicate what we have learned from the data to others. They need to be clear, because we are trying to explain conclusions we have made from intimate knowledge of the data to people who have not worked with it and are trusting us to explain faithfully what we have learned.\nIn libraries, we use explanatory visualiations to improve content discovery for users of our services, and so they can understand our data, as well as for research carried out by librarians and digital humanists that generates new knowledge. The visual routes we supply into data for our users need to be as clear as anything we’re presenting as research.\nHow do we visualise data? There are a huge variety of tools available. Practitioners may lovingly hand draw images (physically or digitally), like early 19th century visualisations by Florence Nightingale and W. E. B. Du Bois and the work, or art, of Federica Fragapane. More commonly there are deeply customisable packages in modern programming languages like R, Python or Javascript, or commercial plotting software like Tableau. Excel has endured through its simple learning curve, ubiquity and reliable outputs. A whole separate suite of software exists for geospatial and linked data. Ultimately the right choice is decided by our use case, data, resources and skills.",
    "crumbs": [
      "Entrance",
      "Data Visualisation"
    ]
  },
  {
    "objectID": "03-dataviz.html#introduction",
    "href": "03-dataviz.html#introduction",
    "title": "Data Visualisation",
    "section": "",
    "text": "Why do we visualise data? For data to tell us something we need to look for patterns, and we are much better at finding these patterns in colours and shapes than in a table of raw data. Visualisations are key to developing the story we want to tell with our data.\nWhen do we visualise data? There are two main moments when working with data that we need to visualise it. First, in the exploratory phase, when we are trying to understand the data, to get insights that lead to fruitful lines of enquiry. These visualisations are rough and ready, meant for us or at most a select few around us to generate debate about what information the data might contain.\nSecond, in the explanatory phase, when we have understood the data and move on to insightful analyses that generate new understanding. These visualisations communicate what we have learned from the data to others. They need to be clear, because we are trying to explain conclusions we have made from intimate knowledge of the data to people who have not worked with it and are trusting us to explain faithfully what we have learned.\nIn libraries, we use explanatory visualiations to improve content discovery for users of our services, and so they can understand our data, as well as for research carried out by librarians and digital humanists that generates new knowledge. The visual routes we supply into data for our users need to be as clear as anything we’re presenting as research.\nHow do we visualise data? There are a huge variety of tools available. Practitioners may lovingly hand draw images (physically or digitally), like early 19th century visualisations by Florence Nightingale and W. E. B. Du Bois and the work, or art, of Federica Fragapane. More commonly there are deeply customisable packages in modern programming languages like R, Python or Javascript, or commercial plotting software like Tableau. Excel has endured through its simple learning curve, ubiquity and reliable outputs. A whole separate suite of software exists for geospatial and linked data. Ultimately the right choice is decided by our use case, data, resources and skills.",
    "crumbs": [
      "Entrance",
      "Data Visualisation"
    ]
  },
  {
    "objectID": "03-dataviz.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "03-dataviz.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "Data Visualisation",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)\nExploratory data visualisations are both quite generic and very dataset specific. Plots like bar charts, histograms, scatter plots, and time series display information in a simple enough way to be reliable and fit the ethos of being quick and informative about the features of your data. Their interpretability also means they are used as explanatory charts, and frequently appear in papers and reports. This Power BI dashboard from Brandi Jagars at University of South Florida Libraries shows how simple visualisations give quick insights into a visitor dataset.\n\n\n\nA dashboard of exploratory graphs.\n\n\nVisualisations designed for publication and for users to consume themselves are much more varied, and (usually) more polished. Ask yourself if you are looking to communicate a succint, unambiguous message or if you are inviting the user to explore the visual.\nMaps are an eye-catching and engaging interface to collections that tap into users’ sense of place. The Mapping Manuscript Migrations project offers a map view of global manuscript migrations allowing users to track the movement of manuscripts filtered by things like collection, author and date of publication.\n\n\n\nMovement of manuscripts from the collection of Sir Thomas Phillipps.\n\n\nPeripleo is a browser-based map viewer that can be used with any cultural heritage dataset with associated location information. It was used in the Heritage for All project to displaying items in hyper-local contexts.\n\n\n\nMap of cultural heritage item locations around Exeter.\n\n\nBoth of these initiatives rely on the concept of Linked Open Data. Each element of linked data is linked to other elements by one of a defined set of relationships, rather than the traditional spreadsheet model where each row is an item with a certain set of properties. This transforms the data into a network, which allows for intuitive, interactive visualisations that let users navigate material contextualised by the items closely linked to it.\nThe Semantic Name Authority Cymru (SNARC) provides views into a linked database of name authority records linked to Wales and the Welsh language. This makes graphs like this family tree of Charlotte Guest, a translator, businesswoman and noble, easy to produce. Displaying parts of the network lets users understand the connections within it, as in this rather large, but very satisfying, graph of Welsh estates, houses and their owners.\n\n\n\nSNARC Welsh estates network graph.\n\n\nThere’s also huge value in making visualisations like this available in physical form within the spaces of a library. The Bohemian Bookshelf was a 2011 project to increase serendipitous book discovery that was installed in the University of Calgary Library. It used 5 different visualisations to ‘entice curiosity’ by taking users to books and authors they might not have otherwise explored. This echoes Dr Mia Ridge’s proposed metric of ‘clicks to curiosity inspired’ in seeking ways to make it easy for users to be inspired by the collection. The ‘book pile’ arranged books by size and page count, acknowledging our natural fascination with the very large and the very small.\n\n\n\nThe Bohemian Bookshelf ‘Book Pile’.\n\n\nYou can explore other use cases in this helpful list from the University of Minnesota Libraries. They’ve catalogued library specific resources for a range of use cases like the teaching, evaluation, and history of data visualisation in libraries.",
    "crumbs": [
      "Entrance",
      "Data Visualisation"
    ]
  },
  {
    "objectID": "03-dataviz.html#hands-on-activityself-guided-tutorials",
    "href": "03-dataviz.html#hands-on-activityself-guided-tutorials",
    "title": "Data Visualisation",
    "section": "Hands-on activity/self-guided tutorial(s)",
    "text": "Hands-on activity/self-guided tutorial(s)\nThe best way to understand the value of data visualisations is to produce them for your datasets. Here are a few tools you can plug datasets into, organised by type and the skills needed to use them.\n\nImmediate results\nRAWGraphs is an online platform (no sign up required) you can upload a spreadsheet to (save it as a CSV first) or a JSON file and point and click your way down the page to produce a visualisation. It’s perfect for exploratory analysis and learning about the different kinds of visualisations available.\nVoyant Tools provides a similarly easy entry for corpus scale text data (whole works, or collections of works), though it helps if you know a little about corpus linguistics. There are ‘pre-built’ corpora of Shakespeare, Austen and Frankenstein available if you don’t have your own files to upload.\n\n\nSpreadsheet-based\nExcel remains such an easy way to interact with spreadsheet data. If you haven’t used it before there are lots of resources available online or your institution may have Microsoft Office skills courses. This six hour course from the Open University (UK) doesn’t assume any knowledge. PowerBI is a more advanced Microsoft Office app that allows you to create dashboards from data. It interfaces easily with Office software, but the visualisations aren’t hugely inspiring. Justin Kelly has an introduction for librarians. Google Charts and Sheets and OpenOffice Calc and Impress are equivalent alternatives.\nTableau is one of many commercial softwares for visualisation. There’s a learning curve similar to Excel, and a free (sign-up required) public platform you can try in browser, use the learning resources to get started.\n\n\nIntro to coding\nThe R for Data Science Data Visualisation tutorial covers using ggplot2, the de facto standard for plotting in R. You can code along with an R environment in your browser using Posit Cloud (requires a free account).\nSeaborn is one of the main plotting packages in Python and follows a similar philosophy to ggplot2. You can code along to their tutorial with a Python environment in browser using Google Colab (requires a Google account).\n\n\nMapping and Linked Data\nGeospatial and linked data (where elements of the data can be explicitly linked to other elements) have their own worlds of tools, with functionality also often covered by the types of tools already listed. ArcGIS (now common in its online form) and QGIS are the most common paid and open source Geographic Information Software (GIS) tools available. You can use these to work with data with geographic components and make display worthy maps. Their outputs also plug into Python, R and JavaScript libraries like leaflet or Dash. Programming Historian have a series of mapping lessons, from an intro to QGIS to converting historical place names into locations on a map.\nFor linked data tools like Gephi or Nodegoat have graphical user interfaces, or there are programming packages like igraph, NetworkX, and D3.js.\n\n\nCommon mistakes\nIt’s tempting for beginners to complicate graphs by adding eye-catching effects like animations or 3D elements. This can, however, make graphs harder to read. When in doubt, opt for simplicity! From Data to Viz has a great page on data visualisation caveats which includes examples of common mistakes and is worth reading.",
    "crumbs": [
      "Entrance",
      "Data Visualisation"
    ]
  },
  {
    "objectID": "03-dataviz.html#recommended-readingviewing",
    "href": "03-dataviz.html#recommended-readingviewing",
    "title": "Data Visualisation",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing\nMuch of data visualisation is communication, and so is deeply subjective. With that in mind there are graphics catalogues that help guide you towards the best visualisation for your purposes. From Data to Viz starts with types of data and leads you to appropriate graphs, while the Financial Times Visual Vocabulary starts with relationships between elements of your data and guides from there. Both are valuable. The EU also maintains a list of generic resources the include some of the ones mentioned here.\nGood visualisations are guided by design philosophies built upon how we process visual information. Two influential books that develop these philosophies are The Grammar of Graphics by Leland Wilkinson and The Visual Display of Quantitative Information (2nd Ed.) by Edward R. Tufte. The Grammar of Graphics is a hefty tome that proposes a core set of components for graphics then builds them from the ground up, with reference to programming. Visual Display is perhaps a little more accessible and relies on the idea of how ink is used (digitally or physically) to understand what is and is not important in a graphic.\nIf visualisation is communication and how we understand visual communication is subjective, then catering generously to how different people process visual information is important. We might call this accessibility. This talk explains some of the basics of how our brains handle colour, and the importance of colour in visualisation. The Seaborn explanation of colour palettes is a helpful reference, and there is a free colour blindness tester to check that your visualisations encode information in colours that everyone can distinguish. Use alt-text for screen reader access and review for keyboard and content accessibility. Harvard have a helpful guide.\n\n\n\nThe importance of colour in recognising categories.",
    "crumbs": [
      "Entrance",
      "Data Visualisation"
    ]
  },
  {
    "objectID": "03-dataviz.html#finding-communities-of-practice",
    "href": "03-dataviz.html#finding-communities-of-practice",
    "title": "Data Visualisation",
    "section": "Finding Communities of Practice",
    "text": "Finding Communities of Practice\nData visualisation, like any other skill, takes practice and familiarity with tools to get the best results. It is, however, relatively easy to make simple but effective visualisations that help you understand your data or explain it to someone else. So take some of your data and begin to play around with it. Play is an important word - you are being creative! It is, unfortunately, just as easy to make bad visualisations that confuse you and your audience. But make good mistakes and do the unexpected as you learn, and you will be better for it. Start simply, more complex visualisations will come with time.\nEngage with designers if they’re available to you and you are producing work for users or the wider public. The art of designing things for people applies as much to data visualisation as it does to anything else.\nHere are some communities that you may want to engage with:\n\nThe Data Visualization Society aiming to “celebrate, nurture, and advance the field of data visualization”, host a range of resources and support the Information is Beautiful Awards each year\nThe Canadian Association of Professional Academic Librarians host a Data Visualization Community of Practice\nGeneral data visualisation groups like Data Viz Singapore may not have all the context for library professionals but are likely to be very welcoming spaces\nThere are a range of data visualisation guides that can act to links to communities in US (university) libraries including Harvard, California State Library, NC State University, Michigan State University\nAny data analysis community of practice is also likely to include and element of data visualisation. Meetup.com may have relevant groups near you.\nLIBER (Ligue des Bibliothèques Européennes de Recherche – Association of European Research Libraries) host a Data Science working group which touches on data visualisation\nSCONUL (UK) have a community of interest for library analytics.\n\nAbove all remember your audience. Keep clear in your mind what it is you are trying to communicate, and to who, and ask yourself if your visualisation does that. Continue to refine it until it does, and you’ll have made a good visualisation.",
    "crumbs": [
      "Entrance",
      "Data Visualisation"
    ]
  },
  {
    "objectID": "contributing.html",
    "href": "contributing.html",
    "title": "Contribute to our Project",
    "section": "",
    "text": "The first edition of Digital Scholarship & Data Science Topic Guides for Library Professionals, launched at the LIBER Annual Conference in Summer 2025, draws heavily on the existing skills framework and topics covered in the British Library’s Digital Scholarship Training Programme, as well as those recommended by attendees of development workshops hosted by LIBER working groups throughout 2023/2024.\nThere are several ways to contribute to the ongoing update and future development of this resource.\nFeel free to contact Nora McGregor if you’re keen to discuss!"
  },
  {
    "objectID": "contributing.html#contribute-a-new-ds-topic-guide",
    "href": "contributing.html#contribute-a-new-ds-topic-guide",
    "title": "Contribute to our Project",
    "section": "Contribute a new DS Topic Guide",
    "text": "Contribute a new DS Topic Guide\n\nChoose from our current wishlist below or propose a brand new one! Not a member of a LIBER Member Institution? Not a problem, we will pair you up with a co-author from the LIBER network to ensure the european research library context is duly represented within the content.\nContact digitalresearch@bl.uk with your idea or feel free to submit a proposal directly on the project GitHub by filling in our New Issue&gt;Submission Tracker template.\nOnce your proposal is reviewed and approved we’ll help you get started right away! Authors will have the option to submit drafts in either of two ways:\n\nUsing a copy of our google doc DS Topic Guide: [Template] and emailing it to digitalresearch@bl.uk\nForking the repository, creating a new guide using the existing template.qmd and submitting a pull request\n\n\n\nNOTE: Our current wishlist for future editions includes but is not limited to topics such as:\n\nClimate Change and Digital Sustainability\nCultural Competency & Ethics in Digital Methods\nDemystifying Computational Environments for Digital Scholarship\nDigital Scholarship/Data Science Project Management, Evaluation and Impact Assessment\nDigital Storytelling\nWikimedia Foundation Projects"
  },
  {
    "objectID": "contributing.html#suggest-edits-to-an-existing-ds-topic-guide",
    "href": "contributing.html#suggest-edits-to-an-existing-ds-topic-guide",
    "title": "Contribute to our Project",
    "section": "Suggest edits to an existing DS Topic Guide",
    "text": "Suggest edits to an existing DS Topic Guide\nKnow of a good case study, report or community of practice that LIBER members should know about? Open a new Issue or add to the discussion on existing Issues on the project Github. If you’re new to GitHub don’t worry, we have a Topic Guide for that: GitHub: How to navigate and contribute to Git-based projects!"
  },
  {
    "objectID": "contributing.html#join-a-working-group-and-help-with-ongoing-maintenance-and-review",
    "href": "contributing.html#join-a-working-group-and-help-with-ongoing-maintenance-and-review",
    "title": "Contribute to our Project",
    "section": "Join a working group and help with ongoing maintenance and review",
    "text": "Join a working group and help with ongoing maintenance and review\nWe view this resource as capturing a snapshot in time and will endeavour to fully review all content a minimum of once annually to check for link rot, and content relevancy. The project team editors are committed to making quick fixes when raised throughout the year, while formal sprints and reviews coinciding with LIBER Annual Summer Conference and Winter events will be used for soliciting new content and undertaking more complex updates to the resource each year and creating new editions as necessary. Join one of the LIBER Working Groups Digital Scholarship and Digital Cultural Heritage WG or Data Science in Libraries (open to all staff of LIBER member institutions) to keep up with the developments and help out with ongoing maintenance of this project!"
  },
  {
    "objectID": "contributing.html#take-part-in-a-writing-sprint",
    "href": "contributing.html#take-part-in-a-writing-sprint",
    "title": "Contribute to our Project",
    "section": "Take part in a Writing Sprint!",
    "text": "Take part in a Writing Sprint!\nWe held four online Topic Guide Sprints in 2024.\n\nTuesday 14 May 2024\nTuesday 03 June 2024\nTuesday 08 October 2024\nTuesday 05 November 2024\n\nTo be notified of future sprints check back here for dates/times or join one of our working groups and we’ll email out the details!\n\nPreparing for a sprint:\n\nPlease have a quick read through the Welcome and DS Topic Guide pages to familiarise yourself with this resource and its purpose.\nWhen you register you’ll see a list of our latest DS Topic Guides on our wishlist. Please check off any and all DS Topic Guides you would be happy to work on during the day of the sprint. On the day each attendee will focus on writing just one DS Topic Guide however. The information you provide before the sprint will help us organise this ahead of time so that as many DS Topic Guides as possible have at least one dedicated author.\n\nPlease have a quick read through the Author Guidance and Style Guide section.\nWe’ll be in touch after we receive your registration to send you more details and useful information ahead of the sprint so look out for our email! If you are sent a copy of the DS Topic Guide Template (Google Doc) that corresponds to your topic of choice ahead of time, add your name to the header, and feel free to add notes or even make a start on drafting your guide before the sprint day if you’re keen!\n\n\n\nWhat to expect on the day:\nA two hour writing sprint will generally follow this format:\n\nWelcome and participant introductions (10 minutes)\n\nOverview of the project & explanation of how the day will run (15 minutes)\n\nAllocation and confirmation of individual Topic Guide Authorship for the day (15 minutes): As a group we’ll go over the wishlist and all participants will be given access to their particular Topic Guide google doc template they’ll be using during and after the sprint.\nWriting Phase (60 minutes): You’ll have an hour to begin writing your respective guide in your Google Doc template. If more than one participant are working together on a topic we can provide breakout rooms so that you can discuss amongst yourselves how to break up the work, and share ideas as you go along. You can have your camera/mic on or off during this time and co-chairs will be on hand to answer any questions or give advice on topics.\nWrapping Up & Logging progress through Github Issues (15 minutes): We have provided an Issue Template which is pre-formatted as a Topic Guide submission checklist and will walk participants through the process of opening a new issue for your draft submission. Please fill in the issue template and provide the necessary information relating to where your draft submission is currently at. Once the issue is saved, it can continue to serve as a space to continue discussion of the ongoing status of your submission and log updates where necessary, including notifying us of when it is fully ready for final review by maintainers.\nClosing Remarks & Next Steps (5 minutes)\n\n\n\nAfter the sprint:\nDuring the sprint, you’ve drafted your DS Topic Guide in a Google Doc. This Google Doc can continue to serve as a ‘living document’ following the sprint until you feel the content is ready to be published. Throughout this process, we will use your Github issue to maintain an overview of the docs in terms of their status and action points so please keep this updated. Each Topic Guide will be allocated a specific Maintainer contact (one of the co-chairs) who will be in touch and work with you to see the process through to completion. You may request placing your Google Doc under restricted access if you wish. We will not do this by default, but we respect that some contributors would like to keep drafts private until fully ready for submission.\nWhen your Topic Guide is ready for our review in Google Docs, please let us know by logging an update over on Github as a comment on the Issue stating this. You can also tag the maintainers so they receive a notification as well. Maintainers will generally work with you on the final edits necessary for the submission through track changes and comments within the Google Doc itself. Once these have all been resolved maintainers will log a status update in the GitHub issue."
  },
  {
    "objectID": "01-computer-vision.html",
    "href": "01-computer-vision.html",
    "title": "Computer Vision",
    "section": "",
    "text": "Computer Vision is a field of Artificial Intelligence (AI) that uses Deep Learning models to teach machines to “see” and interpret images and videos. At its core, Computer Vision involves functions like processing, detection, and analysis of visual data. It uses algorithms to extract meaningful information from images and enables machines to identify objects, recognise patterns, and make decisions based on what they see. Computer Vision powers many of today’s technologies—from facial recognition and object detection to autonomous vehicles, augmented reality, and Video Assistant Referees (VAR) in football. It’s also integral to tools used in cultural heritage and information management, helping libraries automatically tag, classify, and organize vast visual collections such as photographs, manuscripts, and artworks.\nDeep Learning uses neural networks to model complex patterns within data. These networks, much like the human brain, consist of interconnected layers of artificial neurons. During training, these models process massive datasets of images, enabling them to progressively identify features and refine their predictions with increasing accuracy. For instance, a network might initially learn to detect edges and shapes. As training progresses, it learns to identify more complex features such as curves, textures, and ultimately, the entire object itself. This continual process of feature extraction and refinement enables Deep Learning models to achieve remarkable accuracy.\nConvolutional Neural Networks (CNN) have become a cornerstone of image recognition as these neural networks are particularly well-suited for processing grid-like data, such as images. CNNs use convolutional layers that extract local features from the input image (edges, corners, etc.), which are then combined to form more complex representations in subsequent layers, allowing the network to learn hierarchical representations of the image content.\n\n\n\nA diagram showing a convolutional neural network for image classification, progressing from input image to feature learning, flattening, classification, and output probabilities.\n\n\n\n\n\nImage processing - Preparation of input images to enhance them, e.g., noise reduction, sharpening, filtering, extraction of colour, etc.\nObject detection - Identifying specific objects within an image or video (e.g. R-CNN, SSD).\nScene understanding - Analysing the overall context of an image.\nObject classification - Assigning specific objects to a category or class (e.g. AlexNet, VGG).\nImage segmentation - Dividing an image into distinct regions or objects (e.g. U-Net, Mask R-CNN).\nMotion analysis - Tracking the movement of objects within a video (e.g. optical flow).\n\n\n\n\n\nBiases in training data - For example, facial recognition systems trained predominantly on lighter-skinned people struggle to accurately recognise darker-skinned people.\nPrivacy and ethics - The usage of visual and biometric data raises questions regarding privacy and ethics, especially when dealing with black-box models.\nGeneralisation - Models struggle to generalise objects or environments they were not trained on.\nOcclusions - Often objects in an image are partially blocked by other objects, making it difficult for algorithms to correctly identify them. Advanced models, like Mask R-CNN, can help with missing details, but it requires large amounts of training data with occlusion examples.\nFine-graining - Distinguishing between classes or very similar categories is difficult. For instance, it’s relatively easy to differentiate between a cat and a dog, but it is challenging to distinguish dog breeds.\nLighting - Changes in lighting conditions can alter the appearance of objects in an image.\nResource needs - Training and running Deep Learning models require a lot of computational resources.\n\n\n\n\nComputer Vision can be a useful tool in addressing the challenges posed by vast and diverse collections, enabling libraries to improve services and access to knowledge at scale.\n\nImage Classification and Cataloguing - Large digital libraries contain a lot of very different material, which can be hard to manage. Computer Vision can automate classification and cataloguing, reducing the manual work required, and improving discoverability.\nObject Detection and Description - Models can automatically detect features and items in the material, which is useful for creating detailed metadata in large collections. Libraries can also use object detection to improve accessibility by generating descriptive metadata for images and videos.\nAutomatic Text Recognition - Optical Character Recognition (OCR) and Handwritten Text Recognition (HTR) helps libraries to make printed texts and handwritten documents digital. Thus, libraries use OCR/HTR to create searchable digital collections of books, manuscripts, newspapers, etc. OCR/HTR also supports accessibility, enabling text-to-speech conversions for visually impaired users.\nVisual Search and Content-Based Retrieval - Computer Vision improves search functionality in digital libraries through visual search. This allows users to upload an image and retrieve visually similar items from the collection. Content-based image retrieval also supports researchers by enabling them to find works that are similar.",
    "crumbs": [
      "Entrance",
      "Computer Vision"
    ]
  },
  {
    "objectID": "01-computer-vision.html#introduction",
    "href": "01-computer-vision.html#introduction",
    "title": "Computer Vision",
    "section": "",
    "text": "Computer Vision is a field of Artificial Intelligence (AI) that uses Deep Learning models to teach machines to “see” and interpret images and videos. At its core, Computer Vision involves functions like processing, detection, and analysis of visual data. It uses algorithms to extract meaningful information from images and enables machines to identify objects, recognise patterns, and make decisions based on what they see. Computer Vision powers many of today’s technologies—from facial recognition and object detection to autonomous vehicles, augmented reality, and Video Assistant Referees (VAR) in football. It’s also integral to tools used in cultural heritage and information management, helping libraries automatically tag, classify, and organize vast visual collections such as photographs, manuscripts, and artworks.\nDeep Learning uses neural networks to model complex patterns within data. These networks, much like the human brain, consist of interconnected layers of artificial neurons. During training, these models process massive datasets of images, enabling them to progressively identify features and refine their predictions with increasing accuracy. For instance, a network might initially learn to detect edges and shapes. As training progresses, it learns to identify more complex features such as curves, textures, and ultimately, the entire object itself. This continual process of feature extraction and refinement enables Deep Learning models to achieve remarkable accuracy.\nConvolutional Neural Networks (CNN) have become a cornerstone of image recognition as these neural networks are particularly well-suited for processing grid-like data, such as images. CNNs use convolutional layers that extract local features from the input image (edges, corners, etc.), which are then combined to form more complex representations in subsequent layers, allowing the network to learn hierarchical representations of the image content.\n\n\n\nA diagram showing a convolutional neural network for image classification, progressing from input image to feature learning, flattening, classification, and output probabilities.\n\n\n\n\n\nImage processing - Preparation of input images to enhance them, e.g., noise reduction, sharpening, filtering, extraction of colour, etc.\nObject detection - Identifying specific objects within an image or video (e.g. R-CNN, SSD).\nScene understanding - Analysing the overall context of an image.\nObject classification - Assigning specific objects to a category or class (e.g. AlexNet, VGG).\nImage segmentation - Dividing an image into distinct regions or objects (e.g. U-Net, Mask R-CNN).\nMotion analysis - Tracking the movement of objects within a video (e.g. optical flow).\n\n\n\n\n\nBiases in training data - For example, facial recognition systems trained predominantly on lighter-skinned people struggle to accurately recognise darker-skinned people.\nPrivacy and ethics - The usage of visual and biometric data raises questions regarding privacy and ethics, especially when dealing with black-box models.\nGeneralisation - Models struggle to generalise objects or environments they were not trained on.\nOcclusions - Often objects in an image are partially blocked by other objects, making it difficult for algorithms to correctly identify them. Advanced models, like Mask R-CNN, can help with missing details, but it requires large amounts of training data with occlusion examples.\nFine-graining - Distinguishing between classes or very similar categories is difficult. For instance, it’s relatively easy to differentiate between a cat and a dog, but it is challenging to distinguish dog breeds.\nLighting - Changes in lighting conditions can alter the appearance of objects in an image.\nResource needs - Training and running Deep Learning models require a lot of computational resources.\n\n\n\n\nComputer Vision can be a useful tool in addressing the challenges posed by vast and diverse collections, enabling libraries to improve services and access to knowledge at scale.\n\nImage Classification and Cataloguing - Large digital libraries contain a lot of very different material, which can be hard to manage. Computer Vision can automate classification and cataloguing, reducing the manual work required, and improving discoverability.\nObject Detection and Description - Models can automatically detect features and items in the material, which is useful for creating detailed metadata in large collections. Libraries can also use object detection to improve accessibility by generating descriptive metadata for images and videos.\nAutomatic Text Recognition - Optical Character Recognition (OCR) and Handwritten Text Recognition (HTR) helps libraries to make printed texts and handwritten documents digital. Thus, libraries use OCR/HTR to create searchable digital collections of books, manuscripts, newspapers, etc. OCR/HTR also supports accessibility, enabling text-to-speech conversions for visually impaired users.\nVisual Search and Content-Based Retrieval - Computer Vision improves search functionality in digital libraries through visual search. This allows users to upload an image and retrieve visually similar items from the collection. Content-based image retrieval also supports researchers by enabling them to find works that are similar.",
    "crumbs": [
      "Entrance",
      "Computer Vision"
    ]
  },
  {
    "objectID": "01-computer-vision.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "01-computer-vision.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "Computer Vision",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)\nHaving explored the foundational concepts of Computer Vision, let’s now delve into how it is being applied in the library sector. We will take a look at some key applications within areas like collection enrichment, access and delivery, ans well as accessibility.\n\nEnrichment of collections\nComputer Vision is transforming the enrichment of library collections by automating the classification and annotation of visual materials. With the help of object detection and image recognition, it identifies objects, patterns, and relationships within images, enabling the creation of richer metadata and contextual information. This not only improves discoverability, allowing users to locate materials more easily, but also allows for deeper insights into the historical, artistic, or cultural significance of the materials.\nA case study conducted by the University of Calgary’s Libraries and Cultural Resources explored the use of Sheeko, a metadata generation software, to create descriptive metadata from images using pre-trained models. The study concluded that, with moderate human intervention, both the descriptions and titles generated by the pre-trained models were usable. Similarly, the Europeana led project Saint George on a Bike aimed to improve the classification and metadata of cultural heritage objects, by using CNNs for object detection to identify and create semantic context for the images. These examples demonstrate the potential of combining automated AI-powered tools with human expertise to improve metadata creation, while enriching cultural heritage collections and making them more accessible and meaningful for diverse audiences. You can see some examples of how this works in this video about the Saint George on a Bike project:\n\n\n\n\nAccess and delivery\nSimilarly, Computer Vision is improving access, delivery, and research within library collections by enabling more intuitive and sophisticated ways to explore and analyse visual data. Advances in image recognition and retrieval allow users to discover connections, find similar materials, and engage with collections in entirely new ways, improving both the efficiency and depth of exploration.\nFor instance, imgs.ai is a text-based visual search engine designed for digital collections. It uses approximate k-NN algorithms and integrates the OpenAI CLIP model to link textual queries with visually similar content, offering new ways to navigate collections. Similarly, MAKEN, a service developed by the National Library of Norway, uses object detection to identify and retrieve similar images from the library’s digital collection. Thus providing users with yet another possibility of engaging with visual material. These examples show how Computer Vision is making it easier to access digital collections, helping users to find connections, and discover materials quickly and effortlessly.\n\n\n\nScreenshot of MAKEN’s home page. It is in Norwegian and offers a search tool to find similar books or images, with book covers and a search bar displayed on a dark background.\n\n\nPixPlot is a project by the digital humanities lab of Yale University Library, it uses CNNs to cluster similar images.\n\n\nAccessibility\nComputer Vision significantly improves accessibility in libraries by working alongside technologies like OCR and HTR. OCR/HTR convert printed and handwritten texts into machine-readable formats, enabling text-to-speech applications for users with visual impairments. Read more about OCR and HTR from Automatic Text Recognition (OCR/HTR) topic guide.\nBeyond text, Computer Vision enables creation of descriptive metadata for visual materials, such as photographs, maps, or videos, thus providing richer contextual information that benefits users with cognitive or visual disabilities. For instance, a visually impaired user might hear a description of a painting that includes details about the objects and people depicted. This richer contextual information ensures that libraries remain inclusive spaces where all users can access and engage with collections in a meaningful way.\n\n\nSemantic segmentation of maps\nSemantic segmentation in an exciting frontier where Computer Vision can be of use for identifying and categorising distinct elements within maps, such as roads, buildings, water bodies, and land use regions. By using CNNs and U-Net architectures, models partition maps into meaningful segments, allowing for detailed analysis and improved usability. This supports historical research, geographic analysis, and so on, by extracting structured data from cartographic sources.\nFor example, JADIS, developed by the National Library of France, is a tool designed for semantically segmented, georeferenced, and geocoded maps of Paris.\n\n\n\nA vintage map of Paris from 1834 is displayed via JADIS interface, showing streets, buildings, and the Seine River, with navigation and layer options visible on the right.\n\n\nSimilarly, MapReader, an outcome of the Living with Machines project, offers a Computer Vision pipeline for analysing large collections of historical maps.",
    "crumbs": [
      "Entrance",
      "Computer Vision"
    ]
  },
  {
    "objectID": "01-computer-vision.html#hands-on-activityself-guided-tutorials",
    "href": "01-computer-vision.html#hands-on-activityself-guided-tutorials",
    "title": "Computer Vision",
    "section": "Hands-on activity/self-guided tutorial(s)",
    "text": "Hands-on activity/self-guided tutorial(s)\nFor those new to the field, Google Colab Notebooks offer a good starting point with plenty of notebooks on Computer Vision, one great example being this collection.\nThe TensorFlow Playground allows users to experiment with neural network architectures in an interactive way, offering insight into the understanding of how they work.\nGLAM Workbench is a hands-on guide that focuses on applying Computer Vision to GLAM collections, mainly from New Zealand and Australia. It explores how digitised images can be analysed to identify patterns and improve the accessibility of digital heritage.\nIf a more humanities oriented point of view is desired, then Computer Vision related tutorials can also be found at the Programming Historian.\nThe Social Sciences & Humanities Open Marketplace has quite a lot of useful links to free Computer Vision tutorials and training materials worth a look at (search: computer vision).\nFor practical coding experience, versatile tutorials for using open-source tools can be found at OpenCV and RealPython and PyTorch are handy.\nTop universities, for example Harvard, Stanford and Helsinki, offer, sometimes free, online courses as do sites like Coursera, FutureLearn, and Udemy",
    "crumbs": [
      "Entrance",
      "Computer Vision"
    ]
  },
  {
    "objectID": "01-computer-vision.html#recommended-readingviewing",
    "href": "01-computer-vision.html#recommended-readingviewing",
    "title": "Computer Vision",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing\nFor those looking to get a deeper understanding of Computer Vision, some key resources include:\n\nArnold, T., Tilton, L. (2023). Distant viewing: Computational Exploration of Digital Images. The MIT Press. https://doi.org/10.7551/mitpress/14046.001.0001\nKrizhevsky, A., Sutskever, I., Hinton, G. (2012). ImageNet Classification with Deep Convolutional Neural Networks. Advances in Neural Information Processing Systems 25 (NIPS 2012). Retrieved from https://papers.nips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf\nSzeliski, T. (2022). Computer Vision: Algorithms and Applications. Springer. https://doi.org/10.1007/978-3-030-34372-9\nStanford University’s course CS231n Convolutional Neural Networks for Visual Recognition 2016 and 2017 lectures are up on YouTube.",
    "crumbs": [
      "Entrance",
      "Computer Vision"
    ]
  },
  {
    "objectID": "01-computer-vision.html#finding-communities-of-practice",
    "href": "01-computer-vision.html#finding-communities-of-practice",
    "title": "Computer Vision",
    "section": "Finding Communities of Practice",
    "text": "Finding Communities of Practice\nThere are many international communities online where one can join and start to learn more about applications of Computer Vision in libraries and seek support for your own aspirations in this area. Artificial Intelligence for Libraries, Archives and Museums (AI4LAM), CENL network group ‘AI in libraries’, IFLA Artificial Intelligence Special Interest Group and the International Image Interoperability Framework’s (IIIF) AI/ML community group are great places to find and meet others working with Computer Vision in libraries. There are also conferences and events like Fantastic Futures which offer opportunities to learn from and meet like-minded people. The Slack workspaces of AI4LAM or IIIF are open to all and really helpful spaces for asking questions of the community.",
    "crumbs": [
      "Entrance",
      "Computer Vision"
    ]
  },
  {
    "objectID": "06-iiif.html",
    "href": "06-iiif.html",
    "title": "IIIF",
    "section": "",
    "text": "IIIF (pronounced “triple-eye-eff”) stands for the International Image Interoperability Framework. Quite a tongue twister that one, but it broadly represents two things:\n\na set of open standards for delivering high-quality, attributed digital objects online at scale.\nthe open, international community of software developers, libraries, researchers, educators, museums, universities, creative agencies, and more working together to develop and implement the IIIF APIs to make the above open standards happen.\n\n\n\nEver try to look at a large high-resolution digitised manuscript online only for it to take ages to load, and when it finally does you have no way to actually move around the image easily nor see any of the metadata or annotations related to it?\nOr maybe spent months on end negotiating the terms and methods around sending copies of a variety of differently sized individual images to another institution for them to host as part of collaborative project?\nIIIF brings a whole new efficiency to the way in which we in the cultural heritage sector go about sharing and making our digitised collections available online, while greatly expanding the functionality around the way users interact with them. It’s an open standard, collaboratively developed and maintained by a host of cultural heritage institutions around the world that defines a consistent method for the delivery of images and audio/visual files from servers to different environments on the Web where they can then be viewed and interacted with in many ways.\nIIIF basically specifies a way for browsers to display a digital objects such as images, pdfs, audio/visual files and even 3D files in a way that enables much richer functionality on the Web:\n\nMakes it easier to display large images on the web in a way that is scalable (enabling deep zoom)\nAllows easy comparison between two objects, connecting and uniting materials across institutional boundaries\nDisplays structure and metadata and annotations with the digital collection item. (For a digitised manuscript for instance this might be page order and searchable text, for audio/visual materials, that means being able to deliver complex structures (such as several reels of film that make up a single movie) along with things like captions, transcriptions/translations, annotations, and more.)\n\n\n“At its simplest, IIIF uses APIs to load images quickly and zoom smoothly without additional loading time. But IIIF also allows you to do much more, including pulling IIIF-enabled images from different sites into viewers for comparison without downloading them (at full resolution), and enabling saving links to details of images or portions of A/V files for future reference. IIIF also allows you to use many open-source tools that help you to compare, annotate, transcribe, collaborate, and more. You can even gather multiple IIIF images together from across multiple archival collections and/or institutions to create projects or exhibits without advanced technical skills”. -From IIIF for Archives\n\nMaking your collections IIIF enabled makes it easier to share your content online in a consistent way, enabling portability across different IIIF enabled viewers. This means that rather than endlessly creating copies and different access versions of your images to send all over the world for different projects, they can stay on your same IIIF Image server, but be accessed and displayed by viewers hosted at institutions elsewhere in any fashion you require.\n\n\n\nThe IIIF community is made up of over 100 major cultural heritage organisations worldwide who have formally adopted it, including many of our very own LIBER members. It was started in 2011 as a collaboration between The British Library, Stanford University, the Bodleian Libraries (Oxford University), the Bibliothèque nationale de France, Nasjonalbiblioteket (National Library of Norway), Los Alamos National Laboratory Research Library, and Cornell University. It’s a really nice example of an open, grassroots but global community effort, backed by a consortium of leading cultural institutions, who have been working together to develop and implement this new capability for decades and solve their shared problems with delivering, managing, sharing, and working with their resources.\n\n\n\nIf you want the deep nitty gritty technical stuff around all the APIs and how they fit together there is quite a bit of implementation documentation on their website that goes into all this. But essentially, the basic set up behind making your own digitised collections “IIIF enabled”, as they say, looks a little something like this:\n\nSet-up a IIIF image server (you can choose one developed by the community, or there are IIIF-compatible image servers available from vendors or other web hosts), move your content there and implement the IIIF Image API to make those images and audio/video materials available from there.\nImplement the IIIF Presentation API which creates the all important IIIF Manifest files (also many open source or vendor products can help handle this bit too) for each of your objects. This Manifest file is really the prime unit in IIIF, it essentially combines and packages in json code, information about your images and structural data from your metadata source. It lists all the information that makes up your new IIIF enabled object, from how to display it to what information IIIF viewers should (and should not) display (such as structure or the order of pages, or even as minute as where an illustration is located within an image if you like). If you want to see an example of what one looks like this is a IIIF Manifest from the Bodleian Libraries at University of Oxford relating to this collection item. Each manifest has its own URL and that’s the bit you’ll use to do cool things with the object in different IIIF viewers, such as allowing a manuscript to be easily dragged and dropped into Mirador for instance for comparison with other IIIF enabled manuscripts.\nChoose one of the many IIIF enabled viewers for displaying your images and add it to your own collection site. Again, looking at that same collection item record above, note in the upper left hand-corner (see image below) there is an option to view in Mirador or Universal Viewer which are two different styles of IIIF viewer that afford different functionalities.\nConsider making your IIIF Manifests available publicly for download so users can work with them in all the interesting ways you’ve now enabled!\n\n\n\n\nA screenshot of a Bodleian catalogue record showing the IIIF icon and different viewer options.",
    "crumbs": [
      "Entrance",
      "IIIF"
    ]
  },
  {
    "objectID": "06-iiif.html#introduction",
    "href": "06-iiif.html#introduction",
    "title": "IIIF",
    "section": "",
    "text": "IIIF (pronounced “triple-eye-eff”) stands for the International Image Interoperability Framework. Quite a tongue twister that one, but it broadly represents two things:\n\na set of open standards for delivering high-quality, attributed digital objects online at scale.\nthe open, international community of software developers, libraries, researchers, educators, museums, universities, creative agencies, and more working together to develop and implement the IIIF APIs to make the above open standards happen.\n\n\n\nEver try to look at a large high-resolution digitised manuscript online only for it to take ages to load, and when it finally does you have no way to actually move around the image easily nor see any of the metadata or annotations related to it?\nOr maybe spent months on end negotiating the terms and methods around sending copies of a variety of differently sized individual images to another institution for them to host as part of collaborative project?\nIIIF brings a whole new efficiency to the way in which we in the cultural heritage sector go about sharing and making our digitised collections available online, while greatly expanding the functionality around the way users interact with them. It’s an open standard, collaboratively developed and maintained by a host of cultural heritage institutions around the world that defines a consistent method for the delivery of images and audio/visual files from servers to different environments on the Web where they can then be viewed and interacted with in many ways.\nIIIF basically specifies a way for browsers to display a digital objects such as images, pdfs, audio/visual files and even 3D files in a way that enables much richer functionality on the Web:\n\nMakes it easier to display large images on the web in a way that is scalable (enabling deep zoom)\nAllows easy comparison between two objects, connecting and uniting materials across institutional boundaries\nDisplays structure and metadata and annotations with the digital collection item. (For a digitised manuscript for instance this might be page order and searchable text, for audio/visual materials, that means being able to deliver complex structures (such as several reels of film that make up a single movie) along with things like captions, transcriptions/translations, annotations, and more.)\n\n\n“At its simplest, IIIF uses APIs to load images quickly and zoom smoothly without additional loading time. But IIIF also allows you to do much more, including pulling IIIF-enabled images from different sites into viewers for comparison without downloading them (at full resolution), and enabling saving links to details of images or portions of A/V files for future reference. IIIF also allows you to use many open-source tools that help you to compare, annotate, transcribe, collaborate, and more. You can even gather multiple IIIF images together from across multiple archival collections and/or institutions to create projects or exhibits without advanced technical skills”. -From IIIF for Archives\n\nMaking your collections IIIF enabled makes it easier to share your content online in a consistent way, enabling portability across different IIIF enabled viewers. This means that rather than endlessly creating copies and different access versions of your images to send all over the world for different projects, they can stay on your same IIIF Image server, but be accessed and displayed by viewers hosted at institutions elsewhere in any fashion you require.\n\n\n\nThe IIIF community is made up of over 100 major cultural heritage organisations worldwide who have formally adopted it, including many of our very own LIBER members. It was started in 2011 as a collaboration between The British Library, Stanford University, the Bodleian Libraries (Oxford University), the Bibliothèque nationale de France, Nasjonalbiblioteket (National Library of Norway), Los Alamos National Laboratory Research Library, and Cornell University. It’s a really nice example of an open, grassroots but global community effort, backed by a consortium of leading cultural institutions, who have been working together to develop and implement this new capability for decades and solve their shared problems with delivering, managing, sharing, and working with their resources.\n\n\n\nIf you want the deep nitty gritty technical stuff around all the APIs and how they fit together there is quite a bit of implementation documentation on their website that goes into all this. But essentially, the basic set up behind making your own digitised collections “IIIF enabled”, as they say, looks a little something like this:\n\nSet-up a IIIF image server (you can choose one developed by the community, or there are IIIF-compatible image servers available from vendors or other web hosts), move your content there and implement the IIIF Image API to make those images and audio/video materials available from there.\nImplement the IIIF Presentation API which creates the all important IIIF Manifest files (also many open source or vendor products can help handle this bit too) for each of your objects. This Manifest file is really the prime unit in IIIF, it essentially combines and packages in json code, information about your images and structural data from your metadata source. It lists all the information that makes up your new IIIF enabled object, from how to display it to what information IIIF viewers should (and should not) display (such as structure or the order of pages, or even as minute as where an illustration is located within an image if you like). If you want to see an example of what one looks like this is a IIIF Manifest from the Bodleian Libraries at University of Oxford relating to this collection item. Each manifest has its own URL and that’s the bit you’ll use to do cool things with the object in different IIIF viewers, such as allowing a manuscript to be easily dragged and dropped into Mirador for instance for comparison with other IIIF enabled manuscripts.\nChoose one of the many IIIF enabled viewers for displaying your images and add it to your own collection site. Again, looking at that same collection item record above, note in the upper left hand-corner (see image below) there is an option to view in Mirador or Universal Viewer which are two different styles of IIIF viewer that afford different functionalities.\nConsider making your IIIF Manifests available publicly for download so users can work with them in all the interesting ways you’ve now enabled!\n\n\n\n\nA screenshot of a Bodleian catalogue record showing the IIIF icon and different viewer options.",
    "crumbs": [
      "Entrance",
      "IIIF"
    ]
  },
  {
    "objectID": "06-iiif.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "06-iiif.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "IIIF",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)\nIIIF was initiated by a bunch of libraries and cultural heritage collections holders and it shows! It was proposed in late 2011 as a collaboration between The British Library, Stanford University, the Bodleian Libraries (Oxford University), the Bibliothèque nationale de France, Nasjonalbiblioteket (National Library of Norway), Los Alamos National Laboratory Research Library, and Cornell University. The intention of the consortium has always been to combine resource and effort in building viewers that reflected the way we wanted our digital collections to be displayed online, rather than everyone still spending time and resource making our own custom viewers and building our own content silos. It’s brought a huge amount of efficiency too in the way that we share images with each other and researchers. It’s changed the way collaborative projects are undertaken where endless metadata mapping exercises, contract negotiations around re-use and hosting, and the copying and shipping of digitised materials on external hard drives were the norm.\nThere are quite a number of use cases and case studies available on the IIIF Demos page but let’s have a quick look at three real life (and canonical) examples of IIIF in action.\n\nDeep Zoom and Annotations\nThe example here is of the Ōmi Kuni-ezu 近江國絵圖 Japanese Tax map created in 1837. It’s meant to be read in the round by someone standing in the middle–you can see the scale when this zooms out– the map is eleven by seventeen FEET, and the person standing next to it, Wayne who works in the library at Stanford, is six feet four inches tall. This image is a composite of 158 individual images with a file size of 1.27Gb. IIIF allows just enough of an image to be delivered to a viewer–going from a whole image to just the part that they are zooming in on. Without IIIF, an end user might have to download an extremely large file, but using IIIF provides a smooth and easy viewing experience.\n\n\n\nAn image of a man standing next to the Ōmi Kuni-ezu 近江國絵圖 Japanese Tax map to give a sense of the scale of the object.\n\n\nHave a play and view this image in their Mirador viewer here\n\n\nVirtual Reconstruction\nThe virtual reconstruction of this damaged manuscript from Châteauroux in France (Grandes Chroniques de France, ca. 1460) is probably one of the most well-known and best examples of the power of IIIF to support this use case (and my own personal favourite!). At some point in the manuscripts history, fourteen of its illuminations were cut out. These illuminations eventually ended up at the Bibliothèque nationale de France in the 19th century and were digitised individually. In the demo you see the reuniting of the miniatures with the full manuscript as IIIF allows a virtual repositioning of the cut out decorations with the text, virtually reconstructing the manuscript online using the Mirador Viewer so it reflects its original state.\n\n\n\nA screenshot of a digitised manuscript showing a decoration interactively overlayed in the place in which it had been removed.\n\n\nI highly recommend having a play around with the Mirador Viewer: Châteauroux demo.",
    "crumbs": [
      "Entrance",
      "IIIF"
    ]
  },
  {
    "objectID": "06-iiif.html#hands-on-activityself-guided-tutorials",
    "href": "06-iiif.html#hands-on-activityself-guided-tutorials",
    "title": "IIIF",
    "section": "Hands-on activity/self-guided tutorial(s)",
    "text": "Hands-on activity/self-guided tutorial(s)\nThe following tutorials are two of my favourite recommendations for colleagues interested in having a play with IIIF manifests yourself and in the process gaining a practical understanding of how they work, and the benefits!\n\nIIIF Online Workshops The community itself has created a number of excellent and free self-paced tutorials and though they host live online workshops for a fee, these are recorded and available and useful for newcomers for free afterwards. In fact staff at British Library have walked through these self-guided resources online quite often with great success. There is also the opportunity to hire a IIIF Trainer to come to deliver live bespoke training directly to your institution (for a fee), which we have also partaken in!\nWorking with IIIF images in education, communication and research This is a self-guided workshop available online in Dutch and English and has some excellent exercises to get you familiar with finding IIIF manifests in catalogues and importing them into different viewers. I highly recommend making some time (they recommend 120 minutes) to read through this and try out some of the exercises.",
    "crumbs": [
      "Entrance",
      "IIIF"
    ]
  },
  {
    "objectID": "06-iiif.html#recommended-readingviewing",
    "href": "06-iiif.html#recommended-readingviewing",
    "title": "IIIF",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing\nThere is a useful collection of articles and data related to IIIF being compiled by the community on Zenodo\nThe IIIF organisation has also created a number of useful resources alongside their training materials such as How It Works, a plain-language guide to how the IIIF API’s work and a glossary of “Key concepts you’ll encounter when working with IIIF”.\nIt’s worth having a look at how other institutions have provided IIIF Resources.\nThere is also a massive list of learning resources, Awesome IIIF, compiled and maintained by the IIIF Community if you are looking to take your knowledge a bit further and dig deeper into some of the exciting implementations of IIIF.",
    "crumbs": [
      "Entrance",
      "IIIF"
    ]
  },
  {
    "objectID": "06-iiif.html#finding-communities-of-practice",
    "href": "06-iiif.html#finding-communities-of-practice",
    "title": "IIIF",
    "section": "Finding Communities of Practice",
    "text": "Finding Communities of Practice\nLearning about IIIF can be overwhelming at first, especially if you’re not a programmer, but the IIIF Community is a very supportive and engaged one and has created a number of ways to get involved and find support and help.\nI recommend checking out their community page IIIF Community to find details of their next open community calls, or to join their Slack Channel where you can post questions and join the discussion with other users.",
    "crumbs": [
      "Entrance",
      "IIIF"
    ]
  },
  {
    "objectID": "guidelines.html",
    "href": "guidelines.html",
    "title": "Author Guidance & Style Guide",
    "section": "",
    "text": "Each DS Topic Guide follows a distinct structure, beginning with a Header Section (Front Matter) composing of the guide Title, Authors, Affiliations, Published date, Last modified info, and Abstract followed by five key content blocks detailed below. Please have a look at the Getting Started in DS as an example of how these pieces all fit together into one complete DS Topic Guide.\n\n\nThis markdown template shows an example of what information is required for the header, and how each section should be formatted and can be used as the basis for starting a new guide. Note: The project team will ensure each_DS Topic Guide_ is given an individual DOI once published.\n\n\n\nThis section should provide a concise overview of the topic, written in a relaxed and natural way. It does not need to contain the world’s knowledge, just enough high-level knowledge to get the key concepts across. It should be pitched at a beginner/foundational level.\nLinking can be used liberally for terminology and concepts throughout if explaining a particular term is more complex than space allows. Please see the Style Guidelines below for more writing tips!\n\n\n\nThis section provides a clear explanation of the topics’ specific relevance to the work of libraries.\nIt should contain:\n\nA short paragraph or two setting the scene as to why the topic is relevant to the work of libraries. Here you might also like to present opportunities and, if relevant, potential challenges for libraries around the topic as well.\nUp to 3 examples of real world (or potential) applications/case studies/projects, briefly explained, with links to further information if available. Note that it is not necessary to write up or create a new case study or use case yourself here, though you’re more than welcome to! If there are quite a few other examples to include, links to these can be added at the end of the section (Example: “For further case studies, visit….”).\n\n\n\n\nThe objective of this section is to enable learners to familiarise themselves with the basics of the topic through active practice via self-paced tutorials and hand-on activities. Authors are not expected to create new activities or tutorials in this section, but rather to provide selected links to existing hands on tutorials which are known by them to have proven value and can be personally recommended for library professionals in particular.\nThe tutorials recommended should be free, online and suitable for independent study, and ideally, focussed on the library professional perspective where possible. Authors may wish to link to practical exercises or quizzes, specific online lessons that may exist in other online platforms, Juptyer Notebooks and GLAM workbench materials that provide detailed explanations of the steps learners can follow.\nSuggested tutorials should be open access, not behind a paywall.\nFor the sake of consistency across the various topic guides, it is helpful if tutorial references are structured as follows:\n\nThe title/name of the activity/tutorial, the URL (added as a hyperlink) and/or provide a DOI if there is one)\nA brief, personal explanation below it (no more than 200 words) as to why the author recommends this particular tutorial, and, optionally, an indication of topics covered and the level of complexity.\n\n\n\n\nThe section on recommended reading and viewing contains references to more passive learning resources such as:\n\nOpen access articles discussing the topic at a general level, or containing contextual information.\nVideo recordings of lectures about the topic, which do not demand practical activities from the viewer (these can be embedded here)\nPodcasts about the topic\n\nWhen including citations please make sure to provide the DOI with your text if possible so that the project team can compile a dedicated Zotero Library.\nWe discourage adding links and recommendations to materials that are behind paywalls, or otherwise inaccessible easily online/remotely. We recommend use of a VPN for verifying this as sometimes library institution set-ups can make it harder to realise that articles are not free!. If, however, there is an obvious seminal reference work, provide a full reference for it, explain that it is paywalled content or not digitised, and point readers to Worldcat if possible so they can find it in their library.\n\n\n\nThis section provides guidance to library professionals on where they can find networks or additional support from like-minded colleagues for taking their learning journey further. It should include:\n\nWhere to find (local/national/international) Communities of Practice or other relevant networks and organisations who can help with furthering their understanding of the topic.\nIf relevant you might also point to specific summer schools, conferences and other learning events that may further enhance networking and thus learning around a particular topic."
  },
  {
    "objectID": "guidelines.html#structuring-the-ds-topic-guide",
    "href": "guidelines.html#structuring-the-ds-topic-guide",
    "title": "Author Guidance & Style Guide",
    "section": "",
    "text": "Each DS Topic Guide follows a distinct structure, beginning with a Header Section (Front Matter) composing of the guide Title, Authors, Affiliations, Published date, Last modified info, and Abstract followed by five key content blocks detailed below. Please have a look at the Getting Started in DS as an example of how these pieces all fit together into one complete DS Topic Guide.\n\n\nThis markdown template shows an example of what information is required for the header, and how each section should be formatted and can be used as the basis for starting a new guide. Note: The project team will ensure each_DS Topic Guide_ is given an individual DOI once published.\n\n\n\nThis section should provide a concise overview of the topic, written in a relaxed and natural way. It does not need to contain the world’s knowledge, just enough high-level knowledge to get the key concepts across. It should be pitched at a beginner/foundational level.\nLinking can be used liberally for terminology and concepts throughout if explaining a particular term is more complex than space allows. Please see the Style Guidelines below for more writing tips!\n\n\n\nThis section provides a clear explanation of the topics’ specific relevance to the work of libraries.\nIt should contain:\n\nA short paragraph or two setting the scene as to why the topic is relevant to the work of libraries. Here you might also like to present opportunities and, if relevant, potential challenges for libraries around the topic as well.\nUp to 3 examples of real world (or potential) applications/case studies/projects, briefly explained, with links to further information if available. Note that it is not necessary to write up or create a new case study or use case yourself here, though you’re more than welcome to! If there are quite a few other examples to include, links to these can be added at the end of the section (Example: “For further case studies, visit….”).\n\n\n\n\nThe objective of this section is to enable learners to familiarise themselves with the basics of the topic through active practice via self-paced tutorials and hand-on activities. Authors are not expected to create new activities or tutorials in this section, but rather to provide selected links to existing hands on tutorials which are known by them to have proven value and can be personally recommended for library professionals in particular.\nThe tutorials recommended should be free, online and suitable for independent study, and ideally, focussed on the library professional perspective where possible. Authors may wish to link to practical exercises or quizzes, specific online lessons that may exist in other online platforms, Juptyer Notebooks and GLAM workbench materials that provide detailed explanations of the steps learners can follow.\nSuggested tutorials should be open access, not behind a paywall.\nFor the sake of consistency across the various topic guides, it is helpful if tutorial references are structured as follows:\n\nThe title/name of the activity/tutorial, the URL (added as a hyperlink) and/or provide a DOI if there is one)\nA brief, personal explanation below it (no more than 200 words) as to why the author recommends this particular tutorial, and, optionally, an indication of topics covered and the level of complexity.\n\n\n\n\nThe section on recommended reading and viewing contains references to more passive learning resources such as:\n\nOpen access articles discussing the topic at a general level, or containing contextual information.\nVideo recordings of lectures about the topic, which do not demand practical activities from the viewer (these can be embedded here)\nPodcasts about the topic\n\nWhen including citations please make sure to provide the DOI with your text if possible so that the project team can compile a dedicated Zotero Library.\nWe discourage adding links and recommendations to materials that are behind paywalls, or otherwise inaccessible easily online/remotely. We recommend use of a VPN for verifying this as sometimes library institution set-ups can make it harder to realise that articles are not free!. If, however, there is an obvious seminal reference work, provide a full reference for it, explain that it is paywalled content or not digitised, and point readers to Worldcat if possible so they can find it in their library.\n\n\n\nThis section provides guidance to library professionals on where they can find networks or additional support from like-minded colleagues for taking their learning journey further. It should include:\n\nWhere to find (local/national/international) Communities of Practice or other relevant networks and organisations who can help with furthering their understanding of the topic.\nIf relevant you might also point to specific summer schools, conferences and other learning events that may further enhance networking and thus learning around a particular topic."
  },
  {
    "objectID": "guidelines.html#style-guidelines",
    "href": "guidelines.html#style-guidelines",
    "title": "Author Guidance & Style Guide",
    "section": "Style Guidelines",
    "text": "Style Guidelines\n\nThink: Natural, Casual, Accessible, and Internationally Inclusive Content\n\nImagine that a colleague has come to you casually asking about the topic over tea. How might you go about explaining it to them in your own words? During the course of that casual conversation what key things would you leave in and what might you leave out in the interest of getting them to a basic understanding of a complex topic quickly?\n\nThough reviewed and edited by peers, DS Topics Guides are not meant to be written in the style of scholarly papers or journal articles, and instead their style is more in keeping with LibGuides, blogs and personal articles. As such, they should be written in a natural and relaxed manner, but to ensure consistency and inclusivity across our content, please consider these general guidelines:\n\nClarity and Simplicity: Write in a clear and straightforward manner, using simple language that is easy to understand for learners of all backgrounds and proficiency levels.\nLinking to Technical Terms: When introducing technical terms or concepts that may be unfamiliar to some learners, provide hyperlinks to additional resources or definitions where they can learn more. This helps to enhance understanding and allows learners to explore topics in more depth at their own pace. Ensure that the linked resources are reliable and authoritative to provide accurate information to the learners.\nAvoid Colloquialisms and Regionalisms: While it’s essential to maintain a casual and natural tone, please refrain from using colloquial expressions or regionalisms that may not be universally understood by our diverse audience.\nCultural Sensitivity: Be mindful of cultural differences and avoid language or examples that may be offensive or insensitive to any group of people. When providing examples or references, strive for universality and inclusivity.\nGender Neutrality: Use gender-neutral language whenever possible to ensure inclusivity and avoid assumptions about gender roles or identities.\nGlobal Perspective: Consider the international nature of our audience when crafting examples, scenarios, and references. Aim for content that resonates with learners from various cultural backgrounds and geographical locations."
  },
  {
    "objectID": "guidelines.html#checklist-for-authors-reviewerseditors",
    "href": "guidelines.html#checklist-for-authors-reviewerseditors",
    "title": "Author Guidance & Style Guide",
    "section": "Checklist for Authors & Reviewers/Editors",
    "text": "Checklist for Authors & Reviewers/Editors\nThe following checklist reflects the key areas Reviewers and Editors will be checking over with each submitted DS Topic Guide. Authors should find this helpful too and consult it before submitting their work for final review.\n\nFront Matter (for Topic Guides only)\n\nAbstract is clear, concise and reflective of topic\nAuthor names are linked to a LIBER profile where possible or a personal/business bio page\nAuthor orcid id’s are included and resolving correctly\nTitle follows correct capitalisation (Capitalise the first, last and ‘important’ words)\nCheck for references to old “DS Essentials” and replace with “DS Topic Guides”\n\n\n\nContent\n\nContent is clear and complete and follows the Style Guidelines above\nText reflects the aim of the section (for example, Finding Communities of Practice recommends networks/networking/conferences etc. rather than advanced tutorials/lessons)\nImages on the page are directly illustrative of the point/necessary\nCheck for typos\nCheck any activities provided work\nRecommended hands-on activities and self-guided tutorials should be Open Access and freely available online\nRecommended Reading & Viewing content (scholarly texts/articles/books/manuals) should be Open Access by default and not behind a paywall. (We recommend use of a VPN for verifying this as sometimes library institution set-ups can make it harder to realise that articles are not free!) If this is not possible and it is a seminal reference work, provide a full reference for it, explain that it is paywalled content, and point readers to Worldcat if possible so they can find it in their library.\n\n\n\nText Formatting Edits\n\nWritten in British English which is the style of the EU\nCheck for markdown errors\nCheck for references to old “DS Essentials” and replace with “DS Topic Guides”\n“Topic Guides” is always referred to and written in italics as “DS Topic Guides”\n“Digital Scholarship & Data Science Topic Guides for Library Professionals” is always italicised when referenced in text. Note the use of “&” and not “and”\nHeadings are correctly formatted. The title of each guide is already in h1# so main section headers such as “Introduction” should be second-level header with h2 tag ##.\nCapitalise the first, last and ‘important’ words of every heading; for example, ‘Snow White and the Seven Dwarves’.\nReplace Latin abbreviation (eg., ex., etc.,) with full text (Accessibility)\n\n\n\nLinks\n\nCheck all links to ensure there are no broken ones\nInternal links to content within the site (such as reference to other DS Topic Guides) should be relative rather than absolute and use the .qmd extenstion. For example the markdown would look like “See the [IIIF Topic Guide](iiif.qmd).” rather than “See the [IIIF Topic Guide](https://libereurope.github.io/ds-topic-guides/iiif.html).”\nExternal links should include the “https://”\nWe highly discourage linking to articles that are behind paywalled content. However, if it is a seminal reference work, provide a full reference for it, explain that it is paywalled content, and point readers to Worldcat if possible so they can find it in their library.\n\n\n\nImages\n\nImages should be public domain or CC0 as our guides are shared under CC-BY\nImages have alt-tags and captions (Accessibility)\nImages are all saved in the project GitHub folder: https://github.com/libereurope/ds-topic-guides/tree/main/book/images (this will be automated, reviewer can ignore)\nImages are in .jpg or .png or .svg format and ideally less than 1MB (this will be automated, reviewer can ignore)\nImages are no larger than the width of our body text column (width should be less than 949 pixels) (this will be automated, reviewer can ignore)"
  },
  {
    "objectID": "07-digitisation.html",
    "href": "07-digitisation.html",
    "title": "Digitisation: Imaging, 3D and RTI",
    "section": "",
    "text": "Over recent decades research library collections, operations, and audiences have moved from a largely analogue to a mixed analogue/digital environment. So, it will come as no surprise that advances in digital imaging have put digitisation in the position of being one of the most prominent demonstrations of this digital shift. Cultural heritage institutions of all sizes are likely to have some level of digitisation and imaging workflows and standards in place, either through in-house imaging labs or outsourcing through mass digitisation projects like Google Books to keep up with this shift. Many seek to take advantage of uniqueness in their collection by exploiting advanced imaging methods such as 3D modelling, Multispectral Imaging and Reflectance Transformation Imaging (RTI).\nOf course, now that almost everyone has a camera available to them via their phone, it may appear easy for anyone to digitise collection items quickly, or even make their own 3D model, but navigating this complex landscape of technologies, terminologies, methodologies, gadgets and gizmos can be quite daunting for anyone. Those working in cultural heritage institutions also need to consider not just how the technologies work, but how they can be employed within budget, integrated at scale into larger workflows, support preservation alongside access, and be deployed sensitively. This guide aims to help library professionals to understand some of the questions and considerations they need to keep in mind while exploring and having a play with some of these new advanced imaging methods for collection digitisation.\n\n\nIdentifying the right imaging method for different objects, and then the specific technology or combination of them to use can be confusing, and is often restricted by what resources you might have available. Knowing and understanding why you are digitising something from the outset, and what it will be used for, will also inform the decision process, so spend some time thinking about that - the wrong choices can be costly and time consuming. That said, in my experience many of the technologies advance so quickly that whatever you choose, no matter how thoughtfully, will likely be out of date by the time you’ve finished - so my advice is to accept this inevitably, don’t let it stop you, start with a sound approach, do the best with what you can, and know who, and when, to ask for advice!\nHere are brief introductions to some of the advanced imaging methods we have at our disposal:\n\n\n\nMost imaging methods build on a foundation of high quality 2D imaging. You’ll have heard phone manufacturers boasting about how many megapixels their camera has. But this isn’t always an indicator of quality, there are lots of other factors, the more important factor being the size and quality of the imaging sensor. So while using your phone camera may seem a cost-effective and easy solution for digitising collection items, it is unlikely to provide the high-resolution and preservation quality you’re after long term. The guide ‘Remote Capture: Digitising Documentary Heritage in Challenging Locations’ explains this quite well in their chapter on Equipment and skills for digitising in the field. You can see some great examples that demonstrate why high-quality imaging is a must in my case-study.\n\n\n\nAn illustration showing example digital image sensor sizes.\n\n\n\n\n\n3D data can be generated through different methods and technologies. These include photogrammetry, which uses images to obtain accurate measurable information of real-world objects and the terrain, and LIDAR which stands for ‘light detection and ranging’ and is a remote sensing method that uses pulses of light to measure distances and angles as they bounce back into the sensor. The data produced from these methods can then be used to build 3D models of objects or the terrain. 3D models help a user build an understanding of the form of an object, and can even be useful in conveying book construction for example. It works well on most objects, but can run into difficulties with reflective materials like polished glass and metal. Check out some examples in the case-study.\n3D models of cultural heritage objects can then be used in AR/VR/XR environments. You might have come across all three of these terms and been slightly confused as to what the difference is. Augmented reality (AR) is an experience where reality is enhanced in some way using technology. Virtual reality (VR) is usually an entirely simulated experience in which you are immersed. Extended reality (XR) is an umbrella term that encompasses AR, VR or even mixed reality (MR), in which both actual and virtual worlds are merged.\n\n\n\nThis is a method of examining an object under different wavelengths of light – you’ve probably heard of infrared and ultraviolet, but there’s a huge spectrum that can be applied in order to reveal underwriting or investigate faded text and even the structure of the medium, revealing things like paper manufacturing watermarks. Whilst multispectral images can be hard for the average user to interpret, specialists can use them to transcribe long lost texts. For an example of this, you can see a recently rediscovered Merlin Fragment in the IIIF viewer below, or check out the digital edition of the Codex Zacynthius.\n\n\n\n\n\nReflectance Transformation Imaging (RTI) is a technique that creates hyper-real digital images with which the viewer can interact. It creates texture mapping by capturing multiple images of the subject from a fixed point whilst the light source varies in position. This is really useful for revealing the textured detail in surfaces of objects such as coins, engravings or pressed plant material - there are some examples of a herbarium sheet in my case-study. This diagram shows a basic RTI set-up, you can learn more about the technique and process from the Cultural Heritage Imaging’s website about RTI.\n\n\n\nAn illustration showing an example RTI setup, by Andy Corrigan.\n\n\n\n\n\n\nLighting is often as important, if not more so, than the camera you are using, so it pays to learn a bit about that too. For example, a camera sensor is more sensitive to colour temperature and contrast than the human eye. The guide Remote Capture: Digitising Documentary Heritage in Challenging Locations explains a bit more in their section about lighting and flash.\n\nEthics & Cultural Sensitivities Another thing to remember when selecting and preparing to digitise collections is the impact of our own narrative into the process. What we choose to select, our interactions, and the choices we make for providing access to objects, become entwined and embedded through the process of digitisation, and this should be thought through as well. The Digital Preservation Coalition has published a useful guidance note ‘Exploring ethical considerations for providing access to digital heritage collections’, and there is also some interesting discussion in Fafinski’s article ‘Facsimile narratives: Researching the past in the age of digital reproduction’.\nFacsimile, surrogate, object or edition? Opinions often vary on how/what we consider digitised objects to be and what we call them. You may have come across the terms “digital surrogate”, “digital facsimile” or “digital edition” for example. The digitisation process can remove or reduce some aspects, but can add or increase others. Due to this, the outputs of digitisation are now more widely considered to constitute a distinct thing from their real-world original.\nCopyright and licensing is a complex issue, but an essential consideration when digitising anything. You might want to start by looking at the LIBER DS Topic Guide on Copyright.\nHosting Your institution might have one or more hosting solutions on which you can store your digitisation and make it available over the web and integrate it into existing systems. If not, then IIIF might be worth exploring, and a great place to start is the LIBER DS Topic Guide on IIIF. But whilst regular image hosting options are common, more complex digital objects can be a challenge. If you are creating 3D models, RTI or other specialist imaging, you will need to consider a number of options. Many cultural institutions have been hosting their 3D models through a platform called Sketchfab, but at the time of writing, the platform has recently been absorbed into a bigger platform, and its future is in doubt, providing a good example of how challenging it can be relying on third party services. Other options to consider include MorphoSource, a data repository that is more focussed on research and academia, or tools such as Model-Viewer and A-Frame that can be used to build your own virtual experiences. The IIIF community are currently working on support for 3D objects, so keep an eye on developments there!\n\nDigital Preservation is also important to consider - digitisation can be expensive, so don’t risk losing your valuable assets. A great place to start is the Digital Preservation Coalition.",
    "crumbs": [
      "Entrance",
      "Digitisation: Imaging, 3D and RTI"
    ]
  },
  {
    "objectID": "07-digitisation.html#introduction",
    "href": "07-digitisation.html#introduction",
    "title": "Digitisation: Imaging, 3D and RTI",
    "section": "",
    "text": "Over recent decades research library collections, operations, and audiences have moved from a largely analogue to a mixed analogue/digital environment. So, it will come as no surprise that advances in digital imaging have put digitisation in the position of being one of the most prominent demonstrations of this digital shift. Cultural heritage institutions of all sizes are likely to have some level of digitisation and imaging workflows and standards in place, either through in-house imaging labs or outsourcing through mass digitisation projects like Google Books to keep up with this shift. Many seek to take advantage of uniqueness in their collection by exploiting advanced imaging methods such as 3D modelling, Multispectral Imaging and Reflectance Transformation Imaging (RTI).\nOf course, now that almost everyone has a camera available to them via their phone, it may appear easy for anyone to digitise collection items quickly, or even make their own 3D model, but navigating this complex landscape of technologies, terminologies, methodologies, gadgets and gizmos can be quite daunting for anyone. Those working in cultural heritage institutions also need to consider not just how the technologies work, but how they can be employed within budget, integrated at scale into larger workflows, support preservation alongside access, and be deployed sensitively. This guide aims to help library professionals to understand some of the questions and considerations they need to keep in mind while exploring and having a play with some of these new advanced imaging methods for collection digitisation.\n\n\nIdentifying the right imaging method for different objects, and then the specific technology or combination of them to use can be confusing, and is often restricted by what resources you might have available. Knowing and understanding why you are digitising something from the outset, and what it will be used for, will also inform the decision process, so spend some time thinking about that - the wrong choices can be costly and time consuming. That said, in my experience many of the technologies advance so quickly that whatever you choose, no matter how thoughtfully, will likely be out of date by the time you’ve finished - so my advice is to accept this inevitably, don’t let it stop you, start with a sound approach, do the best with what you can, and know who, and when, to ask for advice!\nHere are brief introductions to some of the advanced imaging methods we have at our disposal:\n\n\n\nMost imaging methods build on a foundation of high quality 2D imaging. You’ll have heard phone manufacturers boasting about how many megapixels their camera has. But this isn’t always an indicator of quality, there are lots of other factors, the more important factor being the size and quality of the imaging sensor. So while using your phone camera may seem a cost-effective and easy solution for digitising collection items, it is unlikely to provide the high-resolution and preservation quality you’re after long term. The guide ‘Remote Capture: Digitising Documentary Heritage in Challenging Locations’ explains this quite well in their chapter on Equipment and skills for digitising in the field. You can see some great examples that demonstrate why high-quality imaging is a must in my case-study.\n\n\n\nAn illustration showing example digital image sensor sizes.\n\n\n\n\n\n3D data can be generated through different methods and technologies. These include photogrammetry, which uses images to obtain accurate measurable information of real-world objects and the terrain, and LIDAR which stands for ‘light detection and ranging’ and is a remote sensing method that uses pulses of light to measure distances and angles as they bounce back into the sensor. The data produced from these methods can then be used to build 3D models of objects or the terrain. 3D models help a user build an understanding of the form of an object, and can even be useful in conveying book construction for example. It works well on most objects, but can run into difficulties with reflective materials like polished glass and metal. Check out some examples in the case-study.\n3D models of cultural heritage objects can then be used in AR/VR/XR environments. You might have come across all three of these terms and been slightly confused as to what the difference is. Augmented reality (AR) is an experience where reality is enhanced in some way using technology. Virtual reality (VR) is usually an entirely simulated experience in which you are immersed. Extended reality (XR) is an umbrella term that encompasses AR, VR or even mixed reality (MR), in which both actual and virtual worlds are merged.\n\n\n\nThis is a method of examining an object under different wavelengths of light – you’ve probably heard of infrared and ultraviolet, but there’s a huge spectrum that can be applied in order to reveal underwriting or investigate faded text and even the structure of the medium, revealing things like paper manufacturing watermarks. Whilst multispectral images can be hard for the average user to interpret, specialists can use them to transcribe long lost texts. For an example of this, you can see a recently rediscovered Merlin Fragment in the IIIF viewer below, or check out the digital edition of the Codex Zacynthius.\n\n\n\n\n\nReflectance Transformation Imaging (RTI) is a technique that creates hyper-real digital images with which the viewer can interact. It creates texture mapping by capturing multiple images of the subject from a fixed point whilst the light source varies in position. This is really useful for revealing the textured detail in surfaces of objects such as coins, engravings or pressed plant material - there are some examples of a herbarium sheet in my case-study. This diagram shows a basic RTI set-up, you can learn more about the technique and process from the Cultural Heritage Imaging’s website about RTI.\n\n\n\nAn illustration showing an example RTI setup, by Andy Corrigan.\n\n\n\n\n\n\nLighting is often as important, if not more so, than the camera you are using, so it pays to learn a bit about that too. For example, a camera sensor is more sensitive to colour temperature and contrast than the human eye. The guide Remote Capture: Digitising Documentary Heritage in Challenging Locations explains a bit more in their section about lighting and flash.\n\nEthics & Cultural Sensitivities Another thing to remember when selecting and preparing to digitise collections is the impact of our own narrative into the process. What we choose to select, our interactions, and the choices we make for providing access to objects, become entwined and embedded through the process of digitisation, and this should be thought through as well. The Digital Preservation Coalition has published a useful guidance note ‘Exploring ethical considerations for providing access to digital heritage collections’, and there is also some interesting discussion in Fafinski’s article ‘Facsimile narratives: Researching the past in the age of digital reproduction’.\nFacsimile, surrogate, object or edition? Opinions often vary on how/what we consider digitised objects to be and what we call them. You may have come across the terms “digital surrogate”, “digital facsimile” or “digital edition” for example. The digitisation process can remove or reduce some aspects, but can add or increase others. Due to this, the outputs of digitisation are now more widely considered to constitute a distinct thing from their real-world original.\nCopyright and licensing is a complex issue, but an essential consideration when digitising anything. You might want to start by looking at the LIBER DS Topic Guide on Copyright.\nHosting Your institution might have one or more hosting solutions on which you can store your digitisation and make it available over the web and integrate it into existing systems. If not, then IIIF might be worth exploring, and a great place to start is the LIBER DS Topic Guide on IIIF. But whilst regular image hosting options are common, more complex digital objects can be a challenge. If you are creating 3D models, RTI or other specialist imaging, you will need to consider a number of options. Many cultural institutions have been hosting their 3D models through a platform called Sketchfab, but at the time of writing, the platform has recently been absorbed into a bigger platform, and its future is in doubt, providing a good example of how challenging it can be relying on third party services. Other options to consider include MorphoSource, a data repository that is more focussed on research and academia, or tools such as Model-Viewer and A-Frame that can be used to build your own virtual experiences. The IIIF community are currently working on support for 3D objects, so keep an eye on developments there!\n\nDigital Preservation is also important to consider - digitisation can be expensive, so don’t risk losing your valuable assets. A great place to start is the Digital Preservation Coalition.",
    "crumbs": [
      "Entrance",
      "Digitisation: Imaging, 3D and RTI"
    ]
  },
  {
    "objectID": "07-digitisation.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "07-digitisation.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "Digitisation: Imaging, 3D and RTI",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)\nOne of the biggest benefits to digitising content is often thought of as one of access. Sharing things that have been locked away in our libraries and archives, sometimes for many hundreds of years, to anyone, anywhere in the world with an internet connection is a very powerful thing. This isn’t the only reason or advantage to digitisation - some might be surprising or even more compelling.\nAcknowledgment that the act of digitisation is also an important and valuable part of the research process is steadily growing. For example, over the last few years in the UK, recognition amongst university and research institutions of initiatives such as the Technician Commitment and the Hidden Ref has been increasingly impactful.\n\nCambridge University Library\nBy way of a case study, I wanted to share some stories relating to digitisation here at Cambridge Digital Library. Hopefully these demonstrate just some of the potential and value of digitisation.\nWe are lucky here at Cambridge that a long history of larger scale digitisation projects means we have been able to steadily increase the amount of equipment, skills, and experience we have and the services we can offer researchers. But this activity is more than a service, we work in direct collaboration with researchers, curators, conservators, publishers and exhibitions teams to help them achieve the results they need.\n\n\nFlat digitisation\nAt Cambridge, our focus is very much on delivering the highest possible quality results we can. This is good practice when thinking about the longevity of your outputs, digital preservations needs thinking about at every stage of course, but a major advantage of this approach is that the higher quality the result, the more likely you are to make new discoveries and learn new things about the objects in our care. We have many examples of things that have only been spotted because of the high quality imaging we produce. Take a look at some of the Benefits of Digitisation in this interactive story:\n\n\n\n\n3D and other multidimensional media\nWhilst we might normally expect the written word to occur on a page, the world is more complex than that and even paper isn’t as “flat” as you might expect. Some of the most ancient texts in our collections are Oracle Bones, that are about 3000 years old. They are objects that have undergone a process far more complex than simply marking a flat surface with a pen. They’re materiality is intrinsic to the meaning of the text on their surfaces. But even though something this ancient has been studied for hundreds of years, they are so fragile that most studies are undertaken from impressions of the text (a process which flattens the text for reading and reproduction on the printed page), so it is not often the object is taken out of its carefully constructed archival housing. It was not until the curator saw the 3D model of this oracle bone in the video below, that they noticed there was a surface of it on which there were markings that had never been spotted before!\n\n\nSo, as we can see, 3D modelling can facilitate deeper study and reduce the need to handle fragile objects. But 3D printing them can also be a great way to bring collections to life and enable increased handling via replicas. This is a great way to engage anyone with handling collection items, but can be a particularly pertinent way to bring them to life for people with visual impairments, as we can see in The tale of the ‘Old Horse’ for example:\n\n\nBut 3D models don’t work for everything. In another project we have been collaborating across the other collections at the University of Cambridge to experiment with digitally re-uniting the wide variety of collections relating to Charles Darwin that the University has split over various museums and archives. One particular challenge with this project was presented in the form of herbarium sheets. Plant specimens that Darwin collected on the Beagle Voyage, some of which are now extinct. Whilst the writing on the sheets is well captured by a flat digital image, the plant parts themselves have form and texture, an understanding of which cannot be perceived so well on a flatly lit image. We experimented with 3D modelling them, but ironically they are too flat – the processes involved in 3D modelling didn’t cope well with the flat paper surfaces. Whilst it would be possible to rectify this digitally, it would take a great deal of time, rendering the process extremely inefficient. So we are experimenting with RTI, which allows us to capture texture in a much more engaging way.\nViewing RTI files currently requires specific software, although developments are underway to facilitate the experience through a web browser. The video below demonstrates a few examples that showcase what the experience is like:\n\n\nYou might even find that occasionally people want to see inside something! CT Scanning certainly isn’t an everyday technique that we might associate with research libraries, but you never know. The CT scan shown in the video below is of a fish specimen collected by Charles Darwin on the Beagle Voyage nearly 200 years ago. Preserved in alcohol in a jar, it’s not very easy to inspect or study the real thing:",
    "crumbs": [
      "Entrance",
      "Digitisation: Imaging, 3D and RTI"
    ]
  },
  {
    "objectID": "07-digitisation.html#hands-on-activityself-guided-tutorials",
    "href": "07-digitisation.html#hands-on-activityself-guided-tutorials",
    "title": "Digitisation: Imaging, 3D and RTI",
    "section": "Hands-on activity/self-guided tutorial(s)",
    "text": "Hands-on activity/self-guided tutorial(s)\nIf you’ve got half an hour and a colleague or friend to spare, why not take your first steps into a virtual world and have a go at making a 3D model.\nThe “Big Me, Little Me” exercise has been developed by the team at StoryFutures, and is a great way to start thinking about 3D modelling and the virtual world it creates.\n\n!Warning! - You’ll probably end up wanting to spend longer!\n:-) The question you always need to ask yourself though, is should you?\n\n\nStep 1: Download the Scaniverse App to your mobile device.\n\nStep 2: Scan your friend or colleague. Here are some tips:\n\nMove slowly and as steadily as possible - it also helps if your subject is comfortable and can stay as still as possible.\n\nTry to follow a regular pattern as you move around your subject. Moving in a spiral shape around them from top to bottom can work well.\n\nPay extra attention to heads and faces - avoid starting or stopping with the face as this can result in a visible ‘seam’.\n\n\nStep 3: Process your scan - this might take a few minutes, maybe have a cup of tea.\n\nStep 4: Once your scan is processed, click the “AR View” button. This allows you to play around with the scan in augmented reality, so you can adjust the scale and position. This is the fun bit - you can shrink the scan and get your colleague to adopt a funny pose with a mini version of themselves!\n\nStep 5: Now you can take a screenshot and send it round the team to make everyone smile!",
    "crumbs": [
      "Entrance",
      "Digitisation: Imaging, 3D and RTI"
    ]
  },
  {
    "objectID": "07-digitisation.html#recommended-readingviewing",
    "href": "07-digitisation.html#recommended-readingviewing",
    "title": "Digitisation: Imaging, 3D and RTI",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing\nThere’s loads out there to read-up on that covers everything from the very technical aspects and guidance to the more philosophical side of things - inspiration is everywhere and creative approaches have a habit of seeding into fruitful outcomes!\n\nMaterial Awareness : Exploring the Entanglement of Library Digitization and Digital Textual Scholarship. Martinez, Merisa. (2024). PhD dissertation. Högskolan i Borås.\n\nWhy Do We Digitize? The Case for Slow Digitization. Prescott, Andrew and Hughes, Lorna. (2018). Archive Journal.\n\nA Field Guide to Digital Surrogates: Evaluating and Contextualizing a Rapidly Changing Resource. Stanford, Emma. (2020). In Kathryn Brown (ed.) ‘The Routledge Companion to Digital Humanities and Art History’ (1st ed.). Routledge. Pp 203-214.\n\nDigital humanities and digitised cultural heritage. Terras, Melissa. (2022). In J O’Sullivan (ed.), ‘The Bloomsbury Handbook to the Digital Humanities’ (1st ed.). Bloomsbury Handbooks, Bloomsbury Academic. pp. 255-266.\n\nFacsimile narratives: Researching the past in the age of digital reproduction. Fafinski, Mateusz. (2021). In ‘Digital Scholarship in the Humanities’, Vol. 37. No. 1, 2022.\n\nTechnical Guidance:\n\nRemote Capture: Digitising Documentary Heritage in Challenging Locations. Edited by Jody Butterworth, Andrew Pearson, Patrick Sutherland & Adam Farquhar. (2018). Open Book Publishers.\n\nReflectance Transformation Imaging (RTI). Cultural Heritage Imaging.\n\nFrom Shelf to Europeana: Digitization Workflow Handbook. Europeana.\n\nBasic principles and tips for 3D digitisation of cultural heritage. Europeana (2020).\n\nLearning hub. Association for Historical & Fine Art Photography (AHFAP).\n\nManual for the photography of 3D objects. Rijksmuseum (2017).\n\nTechnical Guidelines for Digitizing Cultural Heritage Materials (3rd ed.). Federal Agencies Digital Guidelines Initiative (FADGI), (2023).\n\nThe London Charter: For the Computer-Based Visualisation of Cultural Heritage. (2009).\nHighlight-Reflectance Transformation Imaging (H-RTI) for Cultural Heritage. Historic England (2018).",
    "crumbs": [
      "Entrance",
      "Digitisation: Imaging, 3D and RTI"
    ]
  },
  {
    "objectID": "07-digitisation.html#finding-communities-of-practice",
    "href": "07-digitisation.html#finding-communities-of-practice",
    "title": "Digitisation: Imaging, 3D and RTI",
    "section": "Finding Communities of Practice",
    "text": "Finding Communities of Practice\nAs we all know, libraries are friendly places and often keen on collaborating. Why not reach out to some libraries with digitisation studios and see if you can go and visit them to learn a bit more about how they operate or what equipment they’re using first hand - it can really help to see a variety of different set-ups in person to start building up an idea of what might work for you. Or try and find a local workshop or summer school to attend that will give you some hands-on experience and the opportunity to meet others like you!",
    "crumbs": [
      "Entrance",
      "Digitisation: Imaging, 3D and RTI"
    ]
  },
  {
    "objectID": "topicguides.html",
    "href": "topicguides.html",
    "title": "Topic Guides",
    "section": "",
    "text": "Authored by LIBER professionals, these guides offer short introductions to applying digital scholarship and data science in modern library work. Each guide includes the authors’ personal recommendations for tutorials, further reading, and communities of practice to support your learning journey.\n\n\n\n\nWhere to begin?\n\n\nOur Getting Started in DS guide provides a helpful starting point for understanding digital scholarship and data science in the context of research libraries!\n\n\n\n\nGroup Study\n\n\nYou can use these materials to kickstart a reading group or host a hands-on workshop. For guidance on setting up your own program, check out our Start your own training programme. It’s packed with tips and tricks from the British Library’s Digital Research Team on how to leverage these guides for group learning within your library or network.\n\n\n\n\n\n\nSelf-study & Quick Reference\n\n\nThese guides offer an initial dive into complex digital scholarship and data science topics, specifically how they apply in libraries. Feel free to explore them in any order, jumping to guides that spark your curiosity or meet your practical needs.\nEach DS Topic Guide is structured to make it easy to quickly find the information you might need:\n\nIntroduction to the topic\nRelevance to the library sector (case studies/use cases)\nHands-on activities and other self-guided tutorial(s)\nRecommended reading & viewing\nFinding Communities of Practice\n\n\n\n\n\n\n\n\n\nTipAre we missing something? Keen to contribute a new guide?\n\n\n\n\n\nWe’d love to hear about it! Vist our Contribute to our Project page for more details. Or just drop us a line at digitalresearch@bl.uk!",
    "crumbs": [
      "Entrance",
      "**Topic Guides**"
    ]
  },
  {
    "objectID": "template.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "template.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "—",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)"
  },
  {
    "objectID": "template.html#hands-on-activityself-guided-tutorials",
    "href": "template.html#hands-on-activityself-guided-tutorials",
    "title": "—",
    "section": "Hands-on activity/self-guided tutorial(s)",
    "text": "Hands-on activity/self-guided tutorial(s)"
  },
  {
    "objectID": "template.html#recommended-reading-viewing",
    "href": "template.html#recommended-reading-viewing",
    "title": "—",
    "section": "Recommended Reading & Viewing",
    "text": "Recommended Reading & Viewing"
  },
  {
    "objectID": "template.html#finding-communities-of-practice",
    "href": "template.html#finding-communities-of-practice",
    "title": "—",
    "section": "Finding Communities of Practice",
    "text": "Finding Communities of Practice"
  },
  {
    "objectID": "licensing.html",
    "href": "licensing.html",
    "title": "Licensing & Re-use",
    "section": "",
    "text": "The project team behind this resource is committed to upholding the values of open source and open science and are keen for the Topic Guides and other content provided here to be used widely and adapted where necessary for local contexts. To enable this, Digital Scholarship & Data Science Topic Guides for Library Professionals, including all Topic Guides published here, are contributed under a CC BY 4.0 Deed | Attribution 4.0 International | Creative Commons license.\nThis means you are free to:\nShare — copy and redistribute the material in any medium or format for any purpose, even commercially.\nAdapt — remix, transform, and build upon the material for any purpose, even commercially.\nThe licensor cannot revoke these freedoms as long as you follow the license terms.\nUnder the following terms:\nAttribution — You must give appropriate credit , provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\nNo additional restrictions — You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits."
  },
  {
    "objectID": "licensing.html#citing-this-resource",
    "href": "licensing.html#citing-this-resource",
    "title": "Licensing & Re-use",
    "section": "Citing this Resource",
    "text": "Citing this Resource\nSuggested citations are written in APA (American Psychological Association) citation style for Journal Articles and are given on each individual guide:\nMcGregor, Nora, “IIIF,” Digital Scholarship & Data Science Topic Guides for Library Professionals (2024), [DOI link]\nTo cite the full resource:\nMcGregor, N., Verhaar, P., Double, J., & Kiraly, P. (Eds.). (2025, March 12). Digital Scholarship & Data Science Topic Guides for Library Professionals. https://libereurope.github.io/ds-topic-guides"
  },
  {
    "objectID": "gettingstarted.html",
    "href": "gettingstarted.html",
    "title": "Getting Started in DS",
    "section": "",
    "text": "In this DS Topic Guide, we aim to help you connect your work in libraries to the world of digital scholarship and data science, and inspire new possibilities for evolving your practices. We’ll provide tips on how to use Digital Scholarship & Data Science Topic Guides for Library Professionals as a personal resource for building new skills. We’ll explore broad definitions of digital scholarship and data science in the context of research libraries, and share key resources to help you understand how emerging technologies and methods are transforming the traditional work of collecting, curating, creating, and sharing in cultural heritage institutions—and why developing skills in this area can be so valuable!\n\n\nThough there are many definitions of what constitutes “digital scholarship” out there, we tend to favour the broadest of interpretations, that is, roughly, any type of innovative research or library activity that combines the methodologies from traditional humanities & social science disciplines with computational tools and digital methods provided by computing disciplines, such as data science.\nThough closely aligned to, and generously informed by, the academic discipline Digital Humanities, “digital scholarship” allows us to consider more broadly the full range of innovative scholarly activities our users seek to undertake with our digital collections and data, across a diverse range of disciplines.\n\n“Digital scholarship” allows us to define a space for us heritage professionals, where research is undertaken, in our own right, during the course of our daily work, utilising computational methods in the curation, creation, collecting and sharing of our digital collections and data, but is not confined to formal academic pursuits or a particular discipline.\n\n\n\n\nNot quite. Data science, also an interdisciplinary academic field, is more specifically focussed on the use of algorithms, machine learning, and statistical modeling to make predictions and uncover deeper insights from noisy, structured, and unstructured data. In libraries, data science is used to improve services, enhance user experiences, and optimize library operations through data-driven insights. Here are a few ways it’s applied:\n\nUser Behavior Analysis: By analyzing data on book checkouts, website visits, and user preferences, libraries can understand which genres or materials are most popular, and tailor their collections accordingly. This helps in making data-informed decisions about acquisitions and promotions.\nPredicting Trends: Data science can help libraries forecast trends — for example, which types of books might become popular in the future or when certain resources are likely to be in demand. This allows libraries to better plan their inventory and schedules.\nImproving Resource Allocation: Libraries can use data science to optimise staffing and the allocation of resources. By examining patterns in library visits, they can predict busy times and adjust staff schedules, ensuring efficient service delivery.\nPersonalized Recommendations: Just like Netflix recommends movies, libraries can use data science to suggest books or resources to users based on their reading history and preferences, making library services more personalized.\nEnhancing User Engagement: By analyzing usage patterns and feedback data, libraries can identify gaps in services or areas for improvement. They can use this information to engage users better and develop targeted programs, like workshops or events, based on what users are interested in.\n\n\nDigital scholarship and data science intersect in ways that are especially valuable for libraries, offering rich possibilities for advancing library services and operations. Digital Scholarship & Data Science Topic Guides for Library Professionals explores these synergies to support informed, innovative library work."
  },
  {
    "objectID": "gettingstarted.html#introduction",
    "href": "gettingstarted.html#introduction",
    "title": "Getting Started in DS",
    "section": "",
    "text": "In this DS Topic Guide, we aim to help you connect your work in libraries to the world of digital scholarship and data science, and inspire new possibilities for evolving your practices. We’ll provide tips on how to use Digital Scholarship & Data Science Topic Guides for Library Professionals as a personal resource for building new skills. We’ll explore broad definitions of digital scholarship and data science in the context of research libraries, and share key resources to help you understand how emerging technologies and methods are transforming the traditional work of collecting, curating, creating, and sharing in cultural heritage institutions—and why developing skills in this area can be so valuable!\n\n\nThough there are many definitions of what constitutes “digital scholarship” out there, we tend to favour the broadest of interpretations, that is, roughly, any type of innovative research or library activity that combines the methodologies from traditional humanities & social science disciplines with computational tools and digital methods provided by computing disciplines, such as data science.\nThough closely aligned to, and generously informed by, the academic discipline Digital Humanities, “digital scholarship” allows us to consider more broadly the full range of innovative scholarly activities our users seek to undertake with our digital collections and data, across a diverse range of disciplines.\n\n“Digital scholarship” allows us to define a space for us heritage professionals, where research is undertaken, in our own right, during the course of our daily work, utilising computational methods in the curation, creation, collecting and sharing of our digital collections and data, but is not confined to formal academic pursuits or a particular discipline.\n\n\n\n\nNot quite. Data science, also an interdisciplinary academic field, is more specifically focussed on the use of algorithms, machine learning, and statistical modeling to make predictions and uncover deeper insights from noisy, structured, and unstructured data. In libraries, data science is used to improve services, enhance user experiences, and optimize library operations through data-driven insights. Here are a few ways it’s applied:\n\nUser Behavior Analysis: By analyzing data on book checkouts, website visits, and user preferences, libraries can understand which genres or materials are most popular, and tailor their collections accordingly. This helps in making data-informed decisions about acquisitions and promotions.\nPredicting Trends: Data science can help libraries forecast trends — for example, which types of books might become popular in the future or when certain resources are likely to be in demand. This allows libraries to better plan their inventory and schedules.\nImproving Resource Allocation: Libraries can use data science to optimise staffing and the allocation of resources. By examining patterns in library visits, they can predict busy times and adjust staff schedules, ensuring efficient service delivery.\nPersonalized Recommendations: Just like Netflix recommends movies, libraries can use data science to suggest books or resources to users based on their reading history and preferences, making library services more personalized.\nEnhancing User Engagement: By analyzing usage patterns and feedback data, libraries can identify gaps in services or areas for improvement. They can use this information to engage users better and develop targeted programs, like workshops or events, based on what users are interested in.\n\n\nDigital scholarship and data science intersect in ways that are especially valuable for libraries, offering rich possibilities for advancing library services and operations. Digital Scholarship & Data Science Topic Guides for Library Professionals explores these synergies to support informed, innovative library work."
  },
  {
    "objectID": "gettingstarted.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "gettingstarted.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "Getting Started in DS",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)\n\nSo what might “digital scholarship and data science in libraries” actually look like?\n\na subject librarian using a digital tool (like OpenRefine) to clean up a set of catalogue records in order to understand gaps in the metadata and collection scope\na collaborative project to automatically transcribe handwritten texts from old manuscripts\na library director reading up on the latest in AI and seeking expert perspectives in order to write a strategy document\na metadata specialist packaging up digital collections into datasets that can be used by researchers\na digitisation project looking to improve the searchability of printed books in under-resourced languages\na marketing analysts using data analytics and data science techniques to understand visitor trends\nan assistant curator attending meetings of an international knowledge exchange networks (such as International GLAM Labs Community)\na reference librarian pointing a researcher to datasets that might help them with their research enquiry\nan imaging technician creating a 3D model of a collection item\na licensing manager keeping up to date on the latest uses of Text and Data Mining (TDM) and AI in research so that digital collections meet the needs of library users and staff who want to work with them at scale\na project manager leading a major interdisciplinary research project using the latest technologies to ask research questions of digital heritage collections\na curator creating an interactive online exhibit with image annotations\na research software engineer using a machine learning model to identify genre of digitised texts\nan assistant librarian attending a summer school on working with cultural heritage data\n\n\n\nWhy is it important for library staff to learn Digital Scholarship and Data Science skills?\nIn the recommended reading section of this DS Topic Guide we have linked to a number of key competency and skills reports and frameworks that define the need for such skills in library work. But in the most high-level terms we know that:\n\nLibraries need to continually keep apace this digital turn in order to understand the change in service requirements and support colleagues and each other keen to make the most of it.\nDigital scholarship work is collaborative, requires input across disciplines and domain expertise, our curatorial experts have an essential role to play in that.\nWe’ve so much to gain from understanding digital methods and having closer collaborations with digital scholars—there’s a synergy in solving shared issues such as correcting OCR, enriching collections metadata, conquering back-cataloguing and so on.\nDigital scholars are, today, using technology in innovative ways, expectations have already changed, they’re seeking access at scale to our collections for computational analysis, they’re using Generative AI to ask their research questions, we need to understand these technologies to understand how the nature of archival enquiry is changing\nCultural heritage digital collections are only going to grow and we need the digital skills to work confidently with them at scale"
  },
  {
    "objectID": "gettingstarted.html#hands-on-activityself-guided-tutorials",
    "href": "gettingstarted.html#hands-on-activityself-guided-tutorials",
    "title": "Getting Started in DS",
    "section": "Hands-on activity/self-guided tutorial(s)",
    "text": "Hands-on activity/self-guided tutorial(s)\nEach DS Topic Guide on this site includes a range of specific hands-on activities and other self-guided tutorials colleagues across Europe personally recommend. When you’re ready to go further and have a better idea of the specific skills you need for a particular task, we can recommend having a good search through these excellent platforms which host or link to a great many in-depth training materials:\n\nAI4Culture https://ai4culture.eu/\nAI4Culture is a capacity building platform for the application of AI in the Cultural Heritage Sector. AI4Culture has been co-funded by the European Union under the Digital Europe Programme. Their aim is to enable professionals, researchers, and enthusiasts within the sector with the resources they need to integrate AI into their daily workflow, find creative ways to use them and solve their current problems. The platform hosts a pool of readily deployed AI software tools, along with training and testing datasets that have been curated for use within the sector.\n\n\nCLARIN Learning Resources https://www.clarin.eu/content/learning-and-training-resources\nCLARIN stands for “Common Language Resources and Technology Infrastructure”, it is a European Research Infrastructure Consortium (ERIC). The CLARIN Learning Hub gives access to open educational resources on various topics of relevance to digital scholarship and data science, including full online training modules to learn these new skills.\n\n\nDARIAH-Campus https://campus.dariah.eu/\nDARIAH stands for “Digital Research Infrastructure for the Arts and Humanities”, like CLARIN it was established as a European Research Infrastructure Consortium (ERIC). As a pan-European infrastructure it supports digital research as well as the teaching of digital research methods for arts and humanities scholars working with computational methods. Though not specific to the library professional context, tutorials here are useful for applying techniques to digital collections.\n\n\nThe Glam Workbench https://glam-workbench.net/\nThe GLAM Workbench is the brainchild of Tim Sherratt, a historian, and is a collection of Jupyter notebooks to help you explore and use data from GLAM institutions (galleries, libraries, archives, and museums). It includes tools, tutorials, examples, hacks, and even some pre-harvested datasets. It is aimed at researchers in the humanities but has useful tutorials for anyone interested in working with GLAM data.\n\n\nIneo https://www.ineo.tools/\nIneo is a project developed and maintained by CLARIAH (“Common Lab Research Infrastructure for the Arts and Humanities”, a collaboration of CLARIN and DARIAH) that lets you search, browse, find and select digital resources for research in humanities and social sciences. It offers access to thousands of tools, datasets, workflows, standards and learning material. It is a work in progress so do keep that in mind when browsing.\n\n\nLibrary Carpentry https://librarycarpentry.org/\nLibrary Carpentry is an international volunteer community, under the Carpentries, focussed building software and data skills within library and information-related communities. The lessons here are meant to be taught as workshops led by a Carpentries certified instructor (for a fee) but you may find it useful to have a read through the content which is open and available to all.\n\n\nThe Programming Historian https://programminghistorian.org/en/\nThe Programming Historian has been publishing peer-reviewed tutorials on digital tools and techniques for humanists since 2008 and though they’re generally aimed at academic researchers, staff at British Library have found them highly useful over the years in their own work!\n\n\nSocial Sciences & Humanities Open Marketplace https://marketplace.sshopencloud.eu/search?order=score&categories=training-material\nBuilt as part of the Social Sciences and Humanities Open Cloud project (SSHOC), the Social Sciences and Humanities Open Marketplace is a discovery portal which pools and contextualises resources for Social Sciences and Humanities research communities: tools, services, training materials, datasets, publications and workflows. The Marketplace highlights and showcases solutions and research practices for every step of the SSH research data life cycle."
  },
  {
    "objectID": "gettingstarted.html#recommended-readingviewing",
    "href": "gettingstarted.html#recommended-readingviewing",
    "title": "Getting Started in DS",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing\nThere is no shortage of recommended reading lists out there, and again, each DS Topic Guide on this site will have their own recommended reading on a particular topic. Here we present a number of key reports and publications which articulate the broad sectoral view of why such skills are necessary for library professionals.\n\nDigital Scholarship & Data Science Skills Competency Frameworks\n\n\nLIBER Publications\n\nLIBER Digital Skills for Library Staff & Researchers Working Group - LIBER Europe have lots of resources here, including a very useful diagram Identifying Open Science Skills for Library Staff & Researchers\nLIBER Job Description Repository Contains job description examples for Digital Curator and other digital roles which reference the types of skills required for such work.\nEurope’s Digital Humanities Landscape: A Study From LIBER’s Digital Humanities & Digital Cultural Heritage Working Group is a report based on a Europe-wide survey run by LIBER’s Digital Humanities & Digital Cultural Heritage Working Group. The survey focused on digital collections and the activities libraries undertake around them. It covered the following topics and themes including staffing/skills\n\n\n\nKey Publications specific to digital scholarship and data science skills for research library staff\n\nAI Competencies for Academic Library Workers\nThe British Library and the Arts and Humanities Research Council published a report on skills: Scoping Skills and Developing Training Programme for Managing Repository Services in Cultural Heritage Organisations. There is a very useful section (Section 3.) that references several other digital skills frameworks for research library staff across Europe.\nLippincott, Joan K. Directions in Digital Scholarship: Support for Digital, Data-Intensive, and Computational Research in Academic Libraries. Coalition for Networked Information, June 2023. https://doi.org/10.56561/ULHJ1168\nPadilla, Thomas. ‘Responsible Operations: Data Science, Machine Learning, and AI in Libraries’. OCLC, 26 August 2020.\nCordell, R. C. (2020). Machine Learning + Libraries: A Report on the State of the Field. LC Labs, Library of Congress.\nFederer L. Defining data librarianship: a survey of competencies, skills, and training. J Med Libr Assoc. 2018 Jul;106(3):294-303. doi: 10.5195/jmla.2018.306. Epub 2018 Jul 1. PMID: 29962907; PMCID: PMC6013124.\n\n\n\nGeneral Competencies for Librarians which include reference to digital\n\nAmerican Library Association (ALA) Library Competencies (Various roles): Library Competencies | Tools, Publications & Resources (ala.org) (USA)\nCanadian Association of Research Libraries Competencies for Librarians in Canadian Research Libraries Publications and Documents (including specifically Competencies-Final-EN-1-2.pdf (Canada)\nCILIP: the library and information association Professional Knowledge & Skills Base - (UK)"
  },
  {
    "objectID": "gettingstarted.html#finding-communities-of-practice",
    "href": "gettingstarted.html#finding-communities-of-practice",
    "title": "Getting Started in DS",
    "section": "Finding Communities of Practice",
    "text": "Finding Communities of Practice\nAs you embark on learning more about digital scholarship and data science in a library context, you might want to explore and join existing communities of practice.\n\nLIBER Working Groups\nWorking groups are open to staff at participating LIBER Member institutions:\n\nLIBER Data Science in Libraries\nLIBER Digital Scholarship & Digital Cultural Heritage\nOr have a look at the other LIBER Working Groups - LIBER Europe\n\n\n\nInternational Communities/Networks\n\nAI4LAM An international, participatory community focused on advancing the use of artificial intelligence in, for and by libraries, archives and museums (Free)\nCode4Lib International, diverse and inclusive community of developers and technologists for libraries, museums, and archives who are dedicated to seeking to share ideas and build collaboration (Free)\nIIIF Community IIIF Groups meet regularly to discuss various contexts of IIIF usage for a particular idea or initiative from technical and non-technical perspectives. (Free)\nIMPACT Centre of Competence IMPACT is a not for profit organisation with the mission to make the digitisation of text “better, faster, cheaper” and to further advance the state-of-the-art in the field of document imaging, language technology and the processing of historical text (Paid membership model)\nInternational GLAM Labs Community An international group dedicated to sharing knowledge around setting up, maintaining and sustaining Galleries, Libraries, Archives and Museums’ cultural heritage innovation Labs (Free)\nMuseums Computer Group The Museums Computer Group (MCG) is a non-profit association of individuals, volunteers, who share a common interest in encouraging, improving and influencing best practice in the use of technology and digital platforms within the museum and heritage sector. (Free to join their discussion list)\nREAD Co-op/Transkribus Community A co-operative organisation, born out of two major EU projects, with the goal of revolutionising access to archival documents by providing a comprehensive range of tools and services that empower researchers, institutions, and individuals with cutting-edge technology such as Handwritten Text Recognition (Paid membership model, but also some free membership options for students and scholars)\n\n\n\nNational Networks (European)\nIreland/UK - RLUK Digital Scholarship Network\n\n\n\n\n\n\nTipAre we missing something?\n\n\n\n\n\nWe’d love to hear it! Suggest edits by opening a new Issue or adding to the discussion on existing Issues on the project Github. If you’re new to GitHub don’t worry, we have a DS Topic Guide for that: GitHub: How to navigate and contribute to Git-based projects! Or just drop us a line at digitalresearch@bl.uk!"
  },
  {
    "objectID": "02-crowdsourcing.html",
    "href": "02-crowdsourcing.html",
    "title": "Crowdsourcing and Citizen Science in Cultural Heritage",
    "section": "",
    "text": "Crowdsourcing in cultural heritage is a method for enabling meaningful public participation in research or practical tasks based on cultural heritage collections or knowledge (adapted from the Collective Wisdom Handbook. In practical terms, a typical example involves asking people outside the institution to contribute effort via tasks such as transcribing, tagging, researching or sharing artefacts. Crowdsourcing projects tend to focus on creating enjoyable, inherently rewarding experiences that lead to high quality data with minimal risk of errors. This means that crowdsourcing platforms can also be a great way for staff to work with their own collections.\nFor example, you could ask locals to share their memories, stories or artefacts about your region, or you could work with the public to co-create an exhibition or collaborate with international experts on research tasks. Some volunteers want follow their interests in specific topics, while others enjoy serendipitious glimpses into varied collections.\nSo perhaps more importantly than the data collected or enhanced, crowdsourcing in cultural heritage is a way of inviting people to spend time with collections and institutions that they might never encounter otherwise. For example, the Living with Machines project engaged over 5000 online volunteers on the citizen science platform, many of whom had no previous experience with library or humanities research, and no previous relationship with the British Library.\nWhile crowdsourcing in other fields might involve payment for tasks completed (for example, via Amazon’s Mechanical Turk), the rewards for contributing to crowdsourcing in cultural heritage are usually intrinsic or altruistic. Thinking of it as a form of online volunteering can be helpful - participants can help enhance collections metadata, research objects or stories, contribute their own knowledge and experience, etc, with opportunities to learn or socialise during the process. But unlike traditional volunteering, crowdsourcing isn’t limited to a venue’s location or hours of operation - online projects can be open to anyone, anywhere in the world, 24 hours a day.\nVolunteers are often motivated by their interest in a topic or source type (e.g. beautiful maps or interesting photographs), the challenge of completing a task well (e.g. deciphering old handwriting), developing their skills and knowledge (e.g. becoming more accurate as they practise palaeography, or learning more about a collection or research question). They often stay motivated because they get feedback from project teams, and gain a sense of purpose or community.\nIncreasingly, libraries might combine crowdsourcing with machine learning and AI tools. For example, by building workflows that automate work such as pre-selecting relevant records, distributing tasks to volunteers with matching skills and interests, then supporting staff in quality checking and formatting the results. Automating tedious (and easily verifiable) tasks with machine learning can help create enjoyable volunteer or staff experiences.\nIt can also be used to ‘scale up’ the results of volunteer work. For example, the ‘Ad or not’ task we created for Living with Machines relies on people’s ability to understand the purpose of short pieces of text - was it an advertisement or part of an article? The results of this task became the ‘ground truth’ dataset for training an experimental machine learning model that could assess whether other texts were ads or not.\n\n\n\nScreenshot of the Zooniverse task interface, with an historical newspaper image on the left, and options to label it ‘yes’ or ‘no’ in response to a question asking if it is an advertisement\n\n\nScreenshot of an early version of the ‘ad or not’ task on Zooniverse. This simple ‘yes or no’ format also meant that the task was available in the Zooniverse app, further increasing its reach.\n\n\n‘Crowdsourcing’ is an awkward name, with implications of ‘outsourcing’ and anonymous crowds, but to date it is the most widely recognised term. Other terms used for similar work include digital public participation, community-generated digital content (CGDC), online volunteering, and variations such as ‘niche-sourcing’ for small or invitation-only projects.\n‘Citizen science’ is another commonly used term with a lot of overlap with crowdsourcing. Citizen science projects might include natural history observations in the world (for example, recording wildlife, or monitoring water quality) or screen-based tasks such as counting penguins in photographs. With roots in a broader concept of ‘science’ (Wissenschaft) as knowledge or areas of study, ‘citizen science’ also includes citizen history, humanities (Geisteswissenschaften), social sciences and any other field that works with knowledge about the world. As inherently interdisciplinary spaces that welcome specialists and the public, libraries are excellent places to host crowdsourcing and citizen science projects.\nWhatever it’s called, recognising the work that volunteers put into projects is important. Some projects do this by hosting events for volunteers, others ensure that they are named and credited in publications and datasets.\n\n\n\nCrowdsourcing isn’t for everyone nor the answer for every need. For example, running a successful project draws on a range of skills, and may require collaboration across many departments in an institution. The development of machine learning / AI methods and increasingly sophisticated crowdsourcing platforms can reduce the amount of work required to gather source material, review and quality control contributions and process the resulting data, but you will still need the resources and inclination for reviewing and sharing progress reports, social interactions with volunteers, and responding to questions. It may take a few iterations to create tasks that produce useful data via tasks that will attract volunteers. If you don’t enjoy talking to volunteers, negotiating with colleagues and wrangling resources (or don’t have any resources to spare), it might not be right for you right now.\nIdeally, you would also be able to ensure that the source collections, desired data results and types of tasks available on your platform of choice are a good match by prototyping or piloting workflows before committing to a full project. That said, you don’t have to limit your project to the types of tasks you’ve seen before - you can invent new tasks and workflows, and work with new technologies to meet your needs. For example, the Living with Machines project invented a ‘close reading’ task that asked volunteers to discern the sense in which specific words were used, supported by computational linguistic analysis.",
    "crumbs": [
      "Entrance",
      "Crowdsourcing and Citizen Science in Cultural Heritage"
    ]
  },
  {
    "objectID": "02-crowdsourcing.html#introduction",
    "href": "02-crowdsourcing.html#introduction",
    "title": "Crowdsourcing and Citizen Science in Cultural Heritage",
    "section": "",
    "text": "Crowdsourcing in cultural heritage is a method for enabling meaningful public participation in research or practical tasks based on cultural heritage collections or knowledge (adapted from the Collective Wisdom Handbook. In practical terms, a typical example involves asking people outside the institution to contribute effort via tasks such as transcribing, tagging, researching or sharing artefacts. Crowdsourcing projects tend to focus on creating enjoyable, inherently rewarding experiences that lead to high quality data with minimal risk of errors. This means that crowdsourcing platforms can also be a great way for staff to work with their own collections.\nFor example, you could ask locals to share their memories, stories or artefacts about your region, or you could work with the public to co-create an exhibition or collaborate with international experts on research tasks. Some volunteers want follow their interests in specific topics, while others enjoy serendipitious glimpses into varied collections.\nSo perhaps more importantly than the data collected or enhanced, crowdsourcing in cultural heritage is a way of inviting people to spend time with collections and institutions that they might never encounter otherwise. For example, the Living with Machines project engaged over 5000 online volunteers on the citizen science platform, many of whom had no previous experience with library or humanities research, and no previous relationship with the British Library.\nWhile crowdsourcing in other fields might involve payment for tasks completed (for example, via Amazon’s Mechanical Turk), the rewards for contributing to crowdsourcing in cultural heritage are usually intrinsic or altruistic. Thinking of it as a form of online volunteering can be helpful - participants can help enhance collections metadata, research objects or stories, contribute their own knowledge and experience, etc, with opportunities to learn or socialise during the process. But unlike traditional volunteering, crowdsourcing isn’t limited to a venue’s location or hours of operation - online projects can be open to anyone, anywhere in the world, 24 hours a day.\nVolunteers are often motivated by their interest in a topic or source type (e.g. beautiful maps or interesting photographs), the challenge of completing a task well (e.g. deciphering old handwriting), developing their skills and knowledge (e.g. becoming more accurate as they practise palaeography, or learning more about a collection or research question). They often stay motivated because they get feedback from project teams, and gain a sense of purpose or community.\nIncreasingly, libraries might combine crowdsourcing with machine learning and AI tools. For example, by building workflows that automate work such as pre-selecting relevant records, distributing tasks to volunteers with matching skills and interests, then supporting staff in quality checking and formatting the results. Automating tedious (and easily verifiable) tasks with machine learning can help create enjoyable volunteer or staff experiences.\nIt can also be used to ‘scale up’ the results of volunteer work. For example, the ‘Ad or not’ task we created for Living with Machines relies on people’s ability to understand the purpose of short pieces of text - was it an advertisement or part of an article? The results of this task became the ‘ground truth’ dataset for training an experimental machine learning model that could assess whether other texts were ads or not.\n\n\n\nScreenshot of the Zooniverse task interface, with an historical newspaper image on the left, and options to label it ‘yes’ or ‘no’ in response to a question asking if it is an advertisement\n\n\nScreenshot of an early version of the ‘ad or not’ task on Zooniverse. This simple ‘yes or no’ format also meant that the task was available in the Zooniverse app, further increasing its reach.\n\n\n‘Crowdsourcing’ is an awkward name, with implications of ‘outsourcing’ and anonymous crowds, but to date it is the most widely recognised term. Other terms used for similar work include digital public participation, community-generated digital content (CGDC), online volunteering, and variations such as ‘niche-sourcing’ for small or invitation-only projects.\n‘Citizen science’ is another commonly used term with a lot of overlap with crowdsourcing. Citizen science projects might include natural history observations in the world (for example, recording wildlife, or monitoring water quality) or screen-based tasks such as counting penguins in photographs. With roots in a broader concept of ‘science’ (Wissenschaft) as knowledge or areas of study, ‘citizen science’ also includes citizen history, humanities (Geisteswissenschaften), social sciences and any other field that works with knowledge about the world. As inherently interdisciplinary spaces that welcome specialists and the public, libraries are excellent places to host crowdsourcing and citizen science projects.\nWhatever it’s called, recognising the work that volunteers put into projects is important. Some projects do this by hosting events for volunteers, others ensure that they are named and credited in publications and datasets.\n\n\n\nCrowdsourcing isn’t for everyone nor the answer for every need. For example, running a successful project draws on a range of skills, and may require collaboration across many departments in an institution. The development of machine learning / AI methods and increasingly sophisticated crowdsourcing platforms can reduce the amount of work required to gather source material, review and quality control contributions and process the resulting data, but you will still need the resources and inclination for reviewing and sharing progress reports, social interactions with volunteers, and responding to questions. It may take a few iterations to create tasks that produce useful data via tasks that will attract volunteers. If you don’t enjoy talking to volunteers, negotiating with colleagues and wrangling resources (or don’t have any resources to spare), it might not be right for you right now.\nIdeally, you would also be able to ensure that the source collections, desired data results and types of tasks available on your platform of choice are a good match by prototyping or piloting workflows before committing to a full project. That said, you don’t have to limit your project to the types of tasks you’ve seen before - you can invent new tasks and workflows, and work with new technologies to meet your needs. For example, the Living with Machines project invented a ‘close reading’ task that asked volunteers to discern the sense in which specific words were used, supported by computational linguistic analysis.",
    "crumbs": [
      "Entrance",
      "Crowdsourcing and Citizen Science in Cultural Heritage"
    ]
  },
  {
    "objectID": "02-crowdsourcing.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "02-crowdsourcing.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "Crowdsourcing and Citizen Science in Cultural Heritage",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)\nCultural heritage institutions can support citizen science projects that ask participants to make observations about the natural world. For example, community science projects at the UK’s Natural History Museum ask people to help investigate noise pollution and local pondlife.\nLibraries, archives and museums can ask volunteers to help create or enhance collection data by transcribing handwritten text, entering data from catalogue or specimen cards into databases, or adding tags or labels to describe images. For example, Smithsonian Digital Volunteers: Transcription Center.\nThey might also ask volunteers to research objects or record information from their personal knowledge. For example, photos on Flickr Commons have been tagged with locations, personal names and histories, and specialist object labels identified by people with local or historical knowledge about photographs.\nLibrary and other GLAM staff can initiate projects, help manage and run them, and check, process and ingest data from crowdsourcing projects. For example, the Library of Congress reviewed comments left on their Flickr Commons images, and updated some of their collections records with information provided by the public.\nLibraries can support projects run on national portals, such as Latvia’s iesaisties.lv. They can point language learners or people with local knowledge to projects in a range of languages and other national portals.\nThere’s a strong relationship between IIIF and crowdsourcing. In 2017 the British Library used IIIF images for the ‘In the Spotlight’ project, in part to save hosting costs, and in part to explore the potential for IIIF annotations in crowdsourcing. This later inspired a collaboration with Zooniverse to support importing media into Zooniverse via IIIF manifests. Crowdsourcing platforms that support IIIF include the Digirati / National Library of Wales/Madoc platform and From the Page.",
    "crumbs": [
      "Entrance",
      "Crowdsourcing and Citizen Science in Cultural Heritage"
    ]
  },
  {
    "objectID": "02-crowdsourcing.html#hands-on-activityself-guided-tutorials",
    "href": "02-crowdsourcing.html#hands-on-activityself-guided-tutorials",
    "title": "Crowdsourcing and Citizen Science in Cultural Heritage",
    "section": "Hands-on activity/self-guided tutorial(s)",
    "text": "Hands-on activity/self-guided tutorial(s)\nThe best way to learn more about crowdsourcing is to try a range of different projects. This will help you understand participant motivations, get a sense of the importance of great titles and instrutions in getting you started, and think about how data might move between GLAM systems and crowdsourcing platforms.\nYou can find projects to try at:\n\nhttps://www.zooniverse.org/projects\nhttps://fromthepage.com/findaproject\nhttps://scistarter.org/\nhttps://transcription.si.edu/\nhttp://lesherbonautes.mnhn.fr/\n\nIf your organisation has records in Europeana, you might be able to devise crowdsourcing tasks for them on the CrowdHeritage site.",
    "crumbs": [
      "Entrance",
      "Crowdsourcing and Citizen Science in Cultural Heritage"
    ]
  },
  {
    "objectID": "02-crowdsourcing.html#recommended-readingviewing",
    "href": "02-crowdsourcing.html#recommended-readingviewing",
    "title": "Crowdsourcing and Citizen Science in Cultural Heritage",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing\nIf you are interested in learning more about participating in, creating or using data from crowdsourcing projects, a recent comprehensive publication is the open access publication, The Collective Wisdom Handbook: Perspectives on Crowdsourcing in Cultural Heritage.\nThe Collective Wisdom Handbook is designed to answer the most common questions that people have as they think about starting, maintaining and using data from a crowdsourcing or citizen science project. Topics covered include:\n\nWhat is crowdsourcing in cultural heritage?\nWhy work with crowdsourcing in cultural heritage?\nIdentifying, aligning, and enacting values in your project\nDesigning cultural heritage crowdsourcing projects\nUnderstanding and connecting to participant motivations\nAligning tasks, platforms, and goals\nChoosing tasks and workflows\nSupporting participants\nWorking with crowdsourced data\nManaging cultural heritage crowdsourcing projects\nConnecting with communities\nPlanning crowdsourcing events\nEvaluating your crowdsourcing project",
    "crumbs": [
      "Entrance",
      "Crowdsourcing and Citizen Science in Cultural Heritage"
    ]
  },
  {
    "objectID": "02-crowdsourcing.html#finding-communities-of-practice",
    "href": "02-crowdsourcing.html#finding-communities-of-practice",
    "title": "Crowdsourcing and Citizen Science in Cultural Heritage",
    "section": "Finding Communities of Practice",
    "text": "Finding Communities of Practice\nWhen you’re ready to think about creating crowdsourcing projects or working with crowdsourcing data it’s useful to reach out to existing communities of practice for support and feedback.\nThe LIBER Citizen Science Working Group is a community of practice open to all LIBER members. They are currently producing a guide for Citizen science in Research Libraries. Topics published to date include:\n\nSkills: Citizen Science skills development for staff, researchers, and the public\nInfrastructures: As being active in the development of infrastructure for researchers to carry out Citizen Science\n\nThe low-traffic JISCMail discussion list on crowdsourcing has many interested members and is a great way to connect with others who have an interest and experience in crowdsourcing in cultural heritage.",
    "crumbs": [
      "Entrance",
      "Crowdsourcing and Citizen Science in Cultural Heritage"
    ]
  }
]